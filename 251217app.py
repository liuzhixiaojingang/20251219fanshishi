import streamlit as st
import pandas as pd
import joblib
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from PIL import Image
import io
import base64
import os
import shap
import networkx as nx
import matplotlib.patches as mpatches

# è®¾ç½®ä¸­æ–‡å­—ä½“ - æ”¾åœ¨æœ€å‰é¢
plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'Arial Unicode MS']
plt.rcParams['axes.unicode_minus'] = False
sns.set(font='SimHei')

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(page_title="çƒ§ä¼¤æ™ºèƒ½è¯†åˆ«ç³»ç»Ÿ", page_icon="ğŸ”¥", layout="wide", initial_sidebar_state="expanded")

# è‡ªå®šä¹‰CSSæ ·å¼
st.markdown("""
<style>
    .main-header { font-size: 2.5rem; color: #ff6b35; text-align: center; margin-bottom: 2rem; font-weight: bold; font-family: "Microsoft YaHei", sans-serif; }
    .sub-header { font-size: 1.5rem; color: #ff8e53; margin: 1rem 0; font-family: "Microsoft YaHei", sans-serif; }
    .feature-box { background-color: #fff5f5; padding: 1rem; border-radius: 10px; border-left: 4px solid #ff6b35; margin: 0.5rem 0; font-family: "Microsoft YaHei", sans-serif; }
    .prediction-box { background: linear-gradient(135deg, #ffecd2 0%, #fcb69f 100%); padding: 1.5rem; border-radius: 15px; text-align: center; margin: 1rem 0; font-family: "Microsoft YaHei", sans-serif; }
    .analysis-box { background: linear-gradient(135deg, #e3f2fd 0%, #bbdefb 100%); padding: 1rem; border-radius: 10px; border-left: 4px solid #2196F3; margin: 1rem 0; font-family: "Microsoft YaHei", sans-serif; }
    .setting-box { background: linear-gradient(135deg, #f0f4f8 0%, #d9e2ec 100%); padding: 1rem; border-radius: 10px; border-left: 4px solid #627d98; margin: 0.5rem 0; font-family: "Microsoft YaHei", sans-serif; }
    .guide-section { background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%); padding: 1.5rem; border-radius: 10px; margin: 1rem 0; border-left: 4px solid #6c757d; font-family: "Microsoft YaHei", sans-serif; }
    .theory-box { background: linear-gradient(135deg, #fff3cd 0%, #ffeaa7 100%); padding: 1rem; border-radius: 8px; margin: 0.5rem 0; border-left: 4px solid #ffc107; font-family: "Microsoft YaHei", sans-serif; }
    .code-box { background-color: #f8f9fa; padding: 1rem; border-radius: 5px; border-left: 4px solid #6c757d; font-family: "Courier New", monospace; margin: 0.5rem 0; }
</style>
""", unsafe_allow_html=True)

# åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
@st.cache_resource
def load_model():
    try:
        model_path = "rf.pkl"
        if os.path.exists(model_path):
            model = joblib.load(model_path)
            if not hasattr(model, 'feature_names_in_'): model.feature_names_in_ = ['BG1', 'EGF', 'IL-1Î²', 'BG2']
            return model
        else:
            st.error(f"âŒ æ¨¡å‹æ–‡ä»¶æœªæ‰¾åˆ°: {model_path}")
            return None
    except Exception as e:
        st.error(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
        return None

# è·å–å›¾è¡¨å­—ä½“è®¾ç½®å‡½æ•°
def get_chart_font_settings():
    """è·å–å›¾è¡¨å­—ä½“è®¾ç½®"""
    return {
        'title_font': st.session_state.get('chart_title_font', {'family': 'Microsoft YaHei', 'size': 14, 'weight': 'bold'}),
        'axis_font': st.session_state.get('chart_axis_font', {'family': 'Microsoft YaHei', 'size': 10}),
        'tick_font': st.session_state.get('chart_tick_font', {'family': 'Microsoft YaHei', 'size': 8}),
        'label_font': st.session_state.get('chart_label_font', {'family': 'Microsoft YaHei', 'size': 9})
    }

# åº”ç”¨å›¾è¡¨å­—ä½“è®¾ç½®å‡½æ•°
def apply_chart_font_settings(ax=None, title=None, xlabel=None, ylabel=None):
    """åº”ç”¨å›¾è¡¨å­—ä½“è®¾ç½®"""
    font_settings = get_chart_font_settings()
    
    if ax is not None:
        # è®¾ç½®æ ‡é¢˜å­—ä½“
        if title and ax.get_title():
            ax.set_title(ax.get_title(), fontfamily=font_settings['title_font']['family'], 
                        fontsize=font_settings['title_font']['size'], fontweight=font_settings['title_font']['weight'])
        
        # è®¾ç½®åæ ‡è½´æ ‡ç­¾å­—ä½“
        if xlabel or ax.get_xlabel():
            ax.set_xlabel(ax.get_xlabel() if not xlabel else xlabel, 
                         fontfamily=font_settings['axis_font']['family'], 
                         fontsize=font_settings['axis_font']['size'])
        
        if ylabel or ax.get_ylabel():
            ax.set_ylabel(ax.get_ylabel() if not ylabel else ylabel, 
                         fontfamily=font_settings['axis_font']['family'], 
                         fontsize=font_settings['axis_font']['size'])
        
        # è®¾ç½®åˆ»åº¦æ ‡ç­¾å­—ä½“
        ax.tick_params(axis='both', which='major', 
                      labelsize=font_settings['tick_font']['size'])
        
        # è®¾ç½®å›¾ä¾‹å­—ä½“ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        legend = ax.get_legend()
        if legend:
            for text in legend.get_texts():
                text.set_fontfamily(font_settings['label_font']['family'])
                text.set_fontsize(font_settings['label_font']['size'])

# SHAPåˆ†æå‡½æ•°
def perform_shap_analysis(model, input_data, feature_names):
    try:
        explainer = shap.TreeExplainer(model)
        shap_values = explainer.shap_values(input_data)
        prediction = model.predict(input_data)[0]
        
        if shap_values.ndim == 3:
            current_shap_values = shap_values[0, :, prediction]
        else:
            st.error(f"ä¸æ”¯æŒçš„SHAPç»´åº¦: {shap_values.ndim}")
            return None
        
        if current_shap_values.ndim > 1: current_shap_values = current_shap_values[0]
        
        feature_importance = np.abs(current_shap_values)
        sorted_idx = np.argsort(feature_importance)[::-1]
        
        return {
            'shap_values': current_shap_values, 'shap_values_3d': shap_values, 'input_data': input_data,
            'feature_importance': feature_importance, 'sorted_features': [feature_names[i] for i in sorted_idx],
            'sorted_importance': feature_importance[sorted_idx], 'prediction': prediction
        }
    except Exception as e:
        st.error(f"SHAPåˆ†æé”™è¯¯: {str(e)}")
        return None

# å›¾1: åˆå¹¶çš„SHAPåˆ†æå›¾è¡¨
def plot_combined_shap_analysis(shap_results, feature_names, burn_type_mapping):
    try:
        if shap_results is None: return None
        shap_values_3d = shap_results['shap_values_3d']
        prediction = shap_results['prediction']
        
        # è·å–å­—ä½“è®¾ç½®
        font_settings = get_chart_font_settings()
        
        # è®¾ç½®å…¨å±€å­—ä½“
        plt.rcParams.update({
            'font.size': font_settings['tick_font']['size'],
            'axes.titlesize': font_settings['title_font']['size'],
            'axes.labelsize': font_settings['axis_font']['size'],
            'xtick.labelsize': font_settings['tick_font']['size'],
            'ytick.labelsize': font_settings['tick_font']['size'],
            'font.family': font_settings['title_font']['family']
        })
        
        fig, axes = plt.subplots(2, 3, figsize=(18, 10))
        fig.suptitle('SHAP Analysis: Feature Impact and Importance for All Classes', 
                     fontsize=font_settings['title_font']['size'] + 2, 
                     fontweight='bold', y=0.95,
                     fontfamily=font_settings['title_font']['family'])
        
        for i in range(6):
            row, col = i // 3, i % 3
            ax = axes[row, col]
            
            if shap_values_3d.ndim == 3:
                class_shap_values = np.mean(shap_values_3d[:, :, i], axis=0)
                class_shap_importance = np.mean(np.abs(shap_values_3d[:, :, i]), axis=0)
            else:
                class_shap_values = shap_values_3d[i]
                class_shap_importance = np.abs(shap_values_3d[i])
            
            sorted_idx = np.argsort(class_shap_importance)[::-1]
            sorted_features = [feature_names[j] for j in sorted_idx]
            sorted_shap = class_shap_values[sorted_idx]
            sorted_importance = class_shap_importance[sorted_idx]
            
            y_pos = np.arange(len(sorted_features))
            colors = ['#ff6b6b' if val > 0 else '#4ecdc4' for val in sorted_shap]
            bars = ax.barh(y_pos, sorted_shap, color=colors, alpha=0.8, height=0.6)
            
            for j, (shap_val, imp_val) in enumerate(zip(sorted_shap, sorted_importance)):
                ax.scatter(imp_val if shap_val >= 0 else -imp_val, j, s=80, color='#2d3436', marker='o', alpha=0.7, zorder=5)
            
            ax.set_yticks(y_pos)
            ax.set_yticklabels(sorted_features, fontfamily=font_settings['tick_font']['family'])
            ax.invert_yaxis()
            ax.axvline(x=0, color='black', linestyle='-', alpha=0.5, linewidth=0.8)
            ax.set_xlabel('SHAP Value / Importance', 
                         fontsize=font_settings['axis_font']['size'], 
                         fontweight='bold',
                         fontfamily=font_settings['axis_font']['family'])
            ax.grid(True, alpha=0.3, axis='x')
            
            if i == prediction:
                ax.patch.set_facecolor('#fffacd')
                ax.patch.set_alpha(0.3)
                for spine in ax.spines.values():
                    spine.set_edgecolor('red')
                    spine.set_linewidth(2)
                title_color = 'red'
                title_suffix = ' â˜…'
            else:
                title_color = 'black'
                title_suffix = ''
            
            ax.set_title(f'Class {i}: {burn_type_mapping[i]["en"]}{title_suffix}', 
                        fontsize=font_settings['title_font']['size'], 
                        fontweight='bold', color=title_color, pad=10,
                        fontfamily=font_settings['title_font']['family'])
            
            for j, (bar, shap_val, imp_val) in enumerate(zip(bars, sorted_shap, sorted_importance)):
                width = bar.get_width()
                if abs(shap_val) > 0.001:
                    if shap_val > 0:
                        ax.text(width + 0.005, bar.get_y() + bar.get_height()/2., f'{shap_val:+.6f}', 
                               ha='left', va='center', 
                               fontsize=font_settings['label_font']['size'] - 1, 
                               color='#d63031', fontweight='bold',
                               fontfamily=font_settings['label_font']['family'])
                    else:
                        ax.text(width - 0.005, bar.get_y() + bar.get_height()/2., f'{shap_val:+.6f}', 
                               ha='right', va='center', 
                               fontsize=font_settings['label_font']['size'] - 1, 
                               color='#00b894', fontweight='bold',
                               fontfamily=font_settings['label_font']['family'])
                    
                    ax.text(imp_val + 0.005 if shap_val >= 0 else -imp_val - 0.005, j, f'{imp_val:.6f}', 
                           ha='left' if shap_val >= 0 else 'right', va='center', 
                           fontsize=font_settings['label_font']['size'] - 2, 
                           color='#2d3436', fontweight='bold',
                           fontfamily=font_settings['label_font']['family'])
        
        plt.tight_layout()
        plt.subplots_adjust(top=0.88)
        
        from matplotlib.patches import Patch
        legend_elements = [
            Patch(facecolor='#ff6b6b', alpha=0.8, label='Positive Impact'),
            Patch(facecolor='#4ecdc4', alpha=0.8, label='Negative Impact'),
            plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='#2d3436', markersize=6, label='Importance Magnitude')
        ]
        fig.legend(handles=legend_elements, loc='upper center', bbox_to_anchor=(0.5, 0.02), ncol=3, 
                  fontsize=font_settings['label_font']['size'], framealpha=0.9, fancybox=True, shadow=True)
        
        return fig
    except Exception as e:
        st.error(f"SHAPå›¾è¡¨ç»˜åˆ¶é”™è¯¯: {str(e)}")
        return None

# å›¾2: å½“å‰é¢„æµ‹ç±»åˆ«çš„ç‰¹å¾é‡è¦æ€§å›¾
def plot_current_prediction_shap(shap_results, feature_names, burn_type_mapping):
    try:
        if shap_results is None: return None
        prediction = shap_results['prediction']
        sorted_features = shap_results['sorted_features']
        sorted_importance = shap_results['sorted_importance']
        
        # è·å–å­—ä½“è®¾ç½®
        font_settings = get_chart_font_settings()
        
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))
        fig.suptitle(f'SHAP Analysis for Current Prediction: {burn_type_mapping[prediction]["en"]}', 
                     fontsize=font_settings['title_font']['size'] + 2, fontweight='bold',
                     fontfamily=font_settings['title_font']['family'])
        
        # å·¦ä¾§ï¼šç‰¹å¾é‡è¦æ€§æ¡å½¢å›¾
        y_pos = np.arange(len(sorted_features))
        colors = plt.cm.viridis(np.linspace(0, 1, len(sorted_features)))
        bars = ax1.barh(y_pos, sorted_importance, color=colors, alpha=0.8)
        ax1.set_yticks(y_pos)
        ax1.set_yticklabels(sorted_features, fontfamily=font_settings['tick_font']['family'])
        ax1.invert_yaxis()
        ax1.set_xlabel('SHAP Value Importance', fontweight='bold',
                       fontfamily=font_settings['axis_font']['family'],
                       fontsize=font_settings['axis_font']['size'])
        ax1.set_title('Feature Importance Ranking', fontweight='bold',
                     fontfamily=font_settings['title_font']['family'],
                     fontsize=font_settings['title_font']['size'])
        ax1.grid(True, alpha=0.3, axis='x')
        
        for bar, importance in zip(bars, sorted_importance):
            width = bar.get_width()
            ax1.text(width + 0.001, bar.get_y() + bar.get_height()/2., f'{width:.10f}', 
                    ha='left', va='center', 
                    fontsize=font_settings['label_font']['size'], fontweight='bold',
                    fontfamily=font_settings['label_font']['family'])
        
        # å³ä¾§ï¼šSHAPå€¼æ­£è´Ÿå½±å“é¥¼å›¾
        shap_values = shap_results['shap_values']
        positive_count = np.sum(shap_values > 0)
        negative_count = np.sum(shap_values < 0)
        neutral_count = np.sum(shap_values == 0)
        
        sizes = [positive_count, negative_count, neutral_count]
        labels = ['Positive Impact', 'Negative Impact', 'No Impact']
        colors = ['#ff6b6b', '#4ecdc4', '#95a5a6']
        
        if sum(sizes) > 0:
            wedges, texts, autotexts = ax2.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90,
                                             textprops={'fontfamily': font_settings['label_font']['family'],
                                                       'fontsize': font_settings['label_font']['size']})
            for autotext in autotexts:
                autotext.set_color('white')
                autotext.set_fontweight('bold')
        else:
            ax2.text(0.5, 0.5, 'No significant\nSHAP values', ha='center', va='center', 
                    transform=ax2.transAxes, fontsize=font_settings['label_font']['size'],
                    fontfamily=font_settings['label_font']['family'])
        
        ax2.set_title('SHAP Value Distribution', fontweight='bold',
                     fontfamily=font_settings['title_font']['family'],
                     fontsize=font_settings['title_font']['size'])
        
        # åº”ç”¨å­—ä½“è®¾ç½®
        apply_chart_font_settings(ax1, xlabel='SHAP Value Importance')
        apply_chart_font_settings(ax2)
        
        plt.tight_layout()
        return fig
    except Exception as e:
        st.error(f"å½“å‰é¢„æµ‹SHAPå›¾è¡¨ç»˜åˆ¶é”™è¯¯: {str(e)}")
        return None

# ä¼˜åŒ–çš„å›¾ç½‘ç»œåˆ†æ
def perform_graph_analysis(feature_values, feature_names, prediction, burn_type_mapping):
    try:
        G = nx.Graph()
        for i, feature in enumerate(feature_names):
            G.add_node(feature, value=feature_values[i], importance=abs(feature_values[i]))
        
        for i in range(len(feature_names)):
            for j in range(i+1, len(feature_names)):
                correlation = 1 - abs(feature_values[i] - feature_values[j]) / (abs(feature_values[i]) + abs(feature_values[j]) + 1e-8)
                if correlation > 0.3:
                    G.add_edge(feature_names[i], feature_names[j], weight=correlation)
        
        degree_centrality = nx.degree_centrality(G)
        betweenness_centrality = nx.betweenness_centrality(G)
        closeness_centrality = nx.closeness_centrality(G)
        
        return {
            'graph': G, 'degree_centrality': degree_centrality, 'betweenness_centrality': betweenness_centrality,
            'closeness_centrality': closeness_centrality, 'node_importance': {feature: abs(val) for feature, val in zip(feature_names, feature_values)}
        }
    except Exception as e:
        st.warning(f"å›¾ç½‘ç»œåˆ†æé‡åˆ°é—®é¢˜: {str(e)}")
        return None

# ä¼˜åŒ–çš„å›¾ç½‘ç»œå¯è§†åŒ–
def plot_optimized_graph_analysis(graph_results, feature_names, burn_info):
    try:
        if graph_results is None: return None
        G = graph_results['graph']
        
        # è·å–å­—ä½“è®¾ç½®
        font_settings = get_chart_font_settings()
        
        fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20, 6))
        fig.suptitle(f'Feature Network Analysis - {burn_info["cn"]}', 
                     fontsize=font_settings['title_font']['size'] + 2, fontweight='bold',
                     fontfamily=font_settings['title_font']['family'])
        
        # å›¾1: ç½‘ç»œæ‹“æ‰‘å›¾
        fig.patch.set_facecolor('white')
        ax1.set_facecolor('white')
        
        pos = nx.spring_layout(G, seed=42, k=3, iterations=200)
        
        node_colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4']
        node_color_map = {feature: node_colors[i] for i, feature in enumerate(feature_names)}
        
        node_sizes = [3000 + 2000 * graph_results['node_importance'][node] for node in G.nodes()]
        node_colors_list = [node_color_map[node] for node in G.nodes()]
        
        nx.draw_networkx_nodes(G, pos, node_size=node_sizes, node_color=node_colors_list, 
                              alpha=0.9, ax=ax1, edgecolors='black', linewidths=2)
        
        edges = G.edges()
        weights = [G[u][v]['weight'] for u,v in edges]
        edge_colors = ['#2C3E50' for _ in edges]
        edge_widths = [w * 5 + 1 for w in weights]
        
        nx.draw_networkx_edges(G, pos, width=edge_widths, 
                              alpha=[min(w * 1.5, 0.8) for w in weights],
                              edge_color=edge_colors, ax=ax1, style='solid')
        
        labels = {node: node for node in G.nodes()}
        nx.draw_networkx_labels(G, pos, labels, font_size=12, 
                              font_weight='bold', ax=ax1,
                              font_family=font_settings['label_font']['family'],
                              bbox=dict(facecolor='white', alpha=0.8, edgecolor='none', pad=1))
        
        ax1.set_title('Network Topology', fontsize=font_settings['title_font']['size'], fontweight='bold',
                     fontfamily=font_settings['title_font']['family'])
        ax1.axis('off')
        
        # å›¾2: ä¸­å¿ƒæ€§åˆ†æé›·è¾¾å›¾
        centrality_data = {
            'Feature': list(graph_results['degree_centrality'].keys()),
            'Degree': list(graph_results['degree_centrality'].values()),
            'Betweenness': list(graph_results['betweenness_centrality'].values()),
            'Closeness': list(graph_results['closeness_centrality'].values())
        }
        df = pd.DataFrame(centrality_data)
        
        categories = list(df['Feature'])
        N = len(categories)
        angles = [n / float(N) * 2 * np.pi for n in range(N)]
        angles += angles[:1]
        
        ax2 = plt.subplot(132, polar=True)
        ax2.set_facecolor('white')
        ax2.set_theta_offset(np.pi / 2)
        ax2.set_theta_direction(-1)
        ax2.set_xticks(angles[:-1])
        ax2.set_xticklabels(categories, fontfamily=font_settings['tick_font']['family'])
        
        values = df['Degree'].values.tolist()
        values += values[:1]
        ax2.plot(angles, values, 'o-', linewidth=2, label='Degree Centrality', color='#e74c3c')
        ax2.fill(angles, values, alpha=0.25, color='#e74c3c')
        
        values = df['Betweenness'].values.tolist()
        values += values[:1]
        ax2.plot(angles, values, 'o-', linewidth=2, label='Betweenness Centrality', color='#3498db')
        ax2.fill(angles, values, alpha=0.25, color='#3498db')
        
        values = df['Closeness'].values.tolist()
        values += values[:1]
        ax2.plot(angles, values, 'o-', linewidth=2, label='Closeness Centrality', color='#2ecc71')
        ax2.fill(angles, values, alpha=0.25, color='#2ecc71')
        
        ax2.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0), 
                  prop={'family': font_settings['label_font']['family'], 'size': font_settings['label_font']['size']})
        ax2.set_title('Centrality Analysis Radar Chart', fontsize=font_settings['title_font']['size'], fontweight='bold',
                     fontfamily=font_settings['title_font']['family'])
        
        # å›¾3: ç‰¹å¾å…³è”çƒ­åŠ›å›¾
        ax3.set_facecolor('white')
        correlation_matrix = np.zeros((len(feature_names), len(feature_names)))
        for i, feat1 in enumerate(feature_names):
            for j, feat2 in enumerate(feature_names):
                if feat1 == feat2:
                    correlation_matrix[i, j] = 1.0
                elif G.has_edge(feat1, feat2):
                    correlation_matrix[i, j] = G[feat1][feat2]['weight']
                else:
                    correlation_matrix[i, j] = 0.0
        
        im = ax3.imshow(correlation_matrix, cmap='RdYlBu_r', vmin=0, vmax=1)
        ax3.set_xticks(range(len(feature_names)))
        ax3.set_yticks(range(len(feature_names)))
        ax3.set_xticklabels(feature_names, rotation=45, fontfamily=font_settings['tick_font']['family'])
        ax3.set_yticklabels(feature_names, fontfamily=font_settings['tick_font']['family'])
        ax3.set_title('Feature Correlation Heatmap', fontsize=font_settings['title_font']['size'], fontweight='bold',
                     fontfamily=font_settings['title_font']['family'])
        
        for i in range(len(feature_names)):
            for j in range(len(feature_names)):
                text = ax3.text(j, i, f'{correlation_matrix[i, j]:.6f}', ha="center", va="center", color="black", 
                              fontsize=font_settings['label_font']['size'] - 1, fontweight='bold',
                              fontfamily=font_settings['label_font']['family'])
        
        plt.colorbar(im, ax=ax3, fraction=0.046, pad=0.04)
        
        apply_chart_font_settings(ax1)
        apply_chart_font_settings(ax2)
        apply_chart_font_settings(ax3)
        
        plt.tight_layout()
        return fig
    except Exception as e:
        st.warning(f"å›¾ç½‘ç»œå¯è§†åŒ–é”™è¯¯: {str(e)}")
        return None

# è®¡ç®—ç»¼åˆç‰¹å¾æƒé‡
def calculate_integrated_feature_weights(shap_results, graph_results, feature_names, alpha=0.4, beta=0.2, gamma=0.2, delta=0.2):
    """
    è®¡ç®—ç»¼åˆç‰¹å¾æƒé‡: w_i = Î±Â·normalize(|Ï•áµ¢|) + Î²Â·normalize(DCáµ¢) + Î³Â·normalize(BCáµ¢) + Î´Â·normalize(CCáµ¢)
    """
    try:
        # 1. SHAPé‡è¦æ€§å½’ä¸€åŒ–
        shap_values = shap_results['shap_values']
        shap_importance = np.abs(shap_values)
        shap_norm = (shap_importance - np.min(shap_importance)) / (np.max(shap_importance) - np.min(shap_importance) + 1e-8)
        
        # 2. å›¾ç½‘ç»œä¸­å¿ƒæ€§å½’ä¸€åŒ–
        dc_values = np.array([graph_results['degree_centrality'][f] for f in feature_names])
        bc_values = np.array([graph_results['betweenness_centrality'][f] for f in feature_names])
        cc_values = np.array([graph_results['closeness_centrality'][f] for f in feature_names])
        
        dc_norm = (dc_values - np.min(dc_values)) / (np.max(dc_values) - np.min(dc_values) + 1e-8)
        bc_norm = (bc_values - np.min(bc_values)) / (np.max(bc_values) - np.min(bc_values) + 1e-8)
        cc_norm = (cc_values - np.min(cc_values)) / (np.max(cc_values) - np.min(cc_values) + 1e-8)
        
        # 3. è®¡ç®—ç»¼åˆæƒé‡
        integrated_weights = alpha * shap_norm + beta * dc_norm + gamma * bc_norm + delta * cc_norm
        
        # 4. å½’ä¸€åŒ–
        integrated_weights = integrated_weights / np.sum(integrated_weights)
        
        return dict(zip(feature_names, integrated_weights))
    
    except Exception as e:
        st.warning(f"è®¡ç®—ç»¼åˆç‰¹å¾æƒé‡é”™è¯¯: {str(e)}")
        return {f: 1.0/len(feature_names) for f in feature_names}  # é»˜è®¤å‡åŒ€åˆ†å¸ƒ

# çƒ§ä¼¤ä¸¥é‡ç¨‹åº¦å®šä¹‰
BURN_SEVERITY_ORDER = [0, 1, 2, 3, 4, 5]  # ä»æœ€è½»åˆ°æœ€é‡

def get_target_priorities(current_class):
    """è·å–ç›®æ ‡ç±»åˆ«ä¼˜å…ˆçº§ï¼ˆä»æœ€ä¼˜å…ˆåˆ°æœ€ä¸ä¼˜å…ˆï¼‰"""
    if current_class not in BURN_SEVERITY_ORDER:
        return []
    
    current_idx = BURN_SEVERITY_ORDER.index(current_class)
    
    # 1. ç›´æ¥æ›´è½»åº¦çƒ§ä¼¤ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
    if current_idx > 0:
        direct_milder = [BURN_SEVERITY_ORDER[current_idx - 1]]
    else:
        direct_milder = []
    
    # 2. å¤šçº§é™çº§
    milder_multi = []
    for i in range(current_idx - 2, -1, -1):
        if i >= 0:
            milder_multi.append(BURN_SEVERITY_ORDER[i])
    
    # 3. æ­£å¸¸ç»„ç»‡ï¼ˆç‰¹æ®Šç›®æ ‡ï¼‰
    normal_tissue = [0] if 0 not in direct_milder + milder_multi else []
    
    # 4. å…¶ä»–ç±»åˆ«
    other_classes = []
    for cls in BURN_SEVERITY_ORDER:
        if cls != current_class and cls not in direct_milder + milder_multi + normal_tissue:
            other_classes.append(cls)
    
    # åˆå¹¶æ‰€æœ‰ä¼˜å…ˆçº§
    all_targets = direct_milder + milder_multi + normal_tissue + other_classes
    
    return all_targets

def find_path_to_target(model, base_values, original_class, target_class, 
                        feature_names, shap_values, max_attempts=20):
    """å¯»æ‰¾ä»å½“å‰ç±»åˆ«åˆ°ç›®æ ‡ç±»åˆ«çš„å¯è¡Œè·¯å¾„"""
    suggestions = []
    n_features = len(feature_names)
    
    # 1. å•ç‰¹å¾ä¿®æ”¹
    for attempt in range(min(max_attempts, 20)):
        for i in range(n_features):
            shap_dir = shap_values[i]
            
            # ç¡®å®šä¿®æ”¹æ–¹å‘
            if shap_dir > 0:
                change_factors = [0.1, 0.3, 0.5, 0.7, 0.9]
            elif shap_dir < 0:
                change_factors = [1.1, 1.3, 1.5, 2.0, 3.0]
            else:
                change_factors = [0.5, 0.7, 1.3, 1.5, 2.0]
            
            for factor in change_factors:
                modified_data = base_values.copy()
                modified_data[i] = base_values[i] * factor
                
                modified_df = pd.DataFrame([modified_data], columns=feature_names)
                new_prediction = model.predict(modified_df)[0]
                new_probability = model.predict_proba(modified_df)[0][new_prediction]
                
                if new_prediction == target_class:
                    suggestions.append({
                        'feature': feature_names[i],
                        'change_factor': factor,
                        'confidence': new_probability,
                        'original_value': base_values[i],
                        'new_value': modified_data[i],
                        'direction': 'å‡å°‘' if factor < 1 else 'å¢åŠ ',
                        'target_class': target_class
                    })
                    
                    if len(suggestions) >= 3:
                        return suggestions
    
    return suggestions

def calculate_improvement(from_class, to_class):
    """è®¡ç®—æ”¹å–„ç¨‹åº¦"""
    if from_class not in BURN_SEVERITY_ORDER or to_class not in BURN_SEVERITY_ORDER:
        return 0
    
    from_idx = BURN_SEVERITY_ORDER.index(from_class)
    to_idx = BURN_SEVERITY_ORDER.index(to_class)
    
    if to_idx < from_idx:  # æ”¹å–„
        if to_class == 0:  # å˜ä¸ºæ­£å¸¸ç»„ç»‡
            return 100
        improvement = (from_idx - to_idx) * 20
        return min(improvement, 80)
    elif to_idx > from_idx:  # æ¶åŒ–
        return -20
    else:  # ä¸å˜
        return 0

# åäº‹å®åˆ†æå‡½æ•° - æ·»åŠ é™çº§å¤„ç†
def perform_counterfactual_analysis(model, input_data, original_prediction, feature_names, burn_type_mapping, shap_results=None, graph_results=None):
    try:
        base_values = input_data.iloc[0].values
        shap_values = shap_results['shap_values'] if shap_results else np.zeros(len(feature_names))
        
        # è®¡ç®—ç‰¹å¾æƒé‡
        feature_weights = {}
        if shap_results and graph_results:
            feature_weights = calculate_integrated_feature_weights(shap_results, graph_results, feature_names)
        else:
            feature_weights = {f: 1.0/len(feature_names) for f in feature_names}
        
        all_suggestions = []
        normal_tissue_suggestions = []
        milder_suggestions = []
        other_suggestions = []
        
        # è·å–ç›®æ ‡ä¼˜å…ˆçº§
        target_priorities = get_target_priorities(original_prediction)
        
        # æŒ‰ä¼˜å…ˆçº§æœç´¢å¯è¡Œè·¯å¾„
        for target_class in target_priorities:
            suggestions = find_path_to_target(
                model, base_values, original_prediction, target_class,
                feature_names, shap_values, max_attempts=20
            )
            
            for sug in suggestions:
                sug['target_class'] = target_class
                sug['target_name'] = burn_type_mapping[target_class]['cn']
                sug['improvement'] = calculate_improvement(original_prediction, target_class)
                sug['weight'] = feature_weights.get(sug['feature'], 0.5)
                sug['efficiency'] = sug['confidence'] * sug['weight']
                
                all_suggestions.append(sug)
                
                if target_class == 0:
                    normal_tissue_suggestions.append(sug)
                elif target_class < original_prediction:
                    milder_suggestions.append(sug)
                else:
                    other_suggestions.append(sug)
        
        # æŒ‰æ•ˆç‡æ’åº
        all_suggestions.sort(key=lambda x: x.get('efficiency', 0), reverse=True)
        normal_tissue_suggestions.sort(key=lambda x: x.get('efficiency', 0), reverse=True)
        milder_suggestions.sort(key=lambda x: x.get('efficiency', 0), reverse=True)
        other_suggestions.sort(key=lambda x: x.get('efficiency', 0), reverse=True)
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä»»ä½•å»ºè®®ï¼Œæä¾›åŸºäºSHAPçš„é€šç”¨å»ºè®®
        if not all_suggestions:
            for i, feature in enumerate(feature_names):
                shap_val = shap_values[i]
                if abs(shap_val) > 0.001:
                    direction = "å‡å°‘" if shap_val > 0 else "å¢åŠ "
                    factor = 0.7 if shap_val > 0 else 1.3
                    
                    all_suggestions.append({
                        'feature': feature,
                        'change_factor': factor,
                        'confidence': 0.3,
                        'original_value': base_values[i],
                        'new_value': base_values[i] * factor,
                        'direction': direction,
                        'target_class': original_prediction,
                        'target_name': burn_type_mapping[original_prediction]['cn'],
                        'improvement': 0,
                        'weight': feature_weights.get(feature, 0.5),
                        'efficiency': 0.15,
                        'is_fallback': True
                    })
        
        return {
            'all_counterfactuals': all_suggestions[:10],
            'normal_tissue_suggestions': normal_tissue_suggestions[:3],
            'milder_suggestions': milder_suggestions[:3],
            'other_suggestions': other_suggestions[:3],
            'original_prediction': original_prediction,
            'feature_weights': feature_weights,
            'shap_directions': dict(zip(feature_names, shap_values)),
            'skip_analysis': False,
            'has_normal_tissue_suggestions': len(normal_tissue_suggestions) > 0
        }
        
    except Exception as e:
        st.warning(f"åäº‹å®åˆ†æé‡åˆ°é—®é¢˜: {str(e)}")
        return {
            'all_counterfactuals': [],
            'normal_tissue_suggestions': [],
            'milder_suggestions': [],
            'other_suggestions': [],
            'original_prediction': original_prediction,
            'skip_analysis': False,
            'has_normal_tissue_suggestions': False
        }

# ä¼˜åŒ–çš„åäº‹å®åˆ†æå¯è§†åŒ–
def plot_optimized_counterfactual_analysis(counterfactual_results, burn_type_mapping):
    try:
        if not counterfactual_results or counterfactual_results.get('skip_analysis', False):
            return create_no_results_plot("æ— åäº‹å®åˆ†æç»“æœ")
        
        all_suggestions = counterfactual_results.get('all_counterfactuals', [])
        if not all_suggestions:
            return create_no_results_plot("æœªæ‰¾åˆ°å¯è¡Œçš„ç‰¹å¾è°ƒæ•´æ–¹æ¡ˆ")
        
        # è·å–å­—ä½“è®¾ç½®
        font_settings = get_chart_font_settings()
        
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        fig.suptitle(f'åäº‹å®åˆ†æ - çƒ§ä¼¤ç­‰çº§æ”¹å–„ç­–ç•¥ (å½“å‰: {burn_type_mapping[counterfactual_results["original_prediction"]]["cn"]})', 
                     fontsize=font_settings['title_font']['size'] + 2, fontweight='bold',
                     fontfamily=font_settings['title_font']['family'])
        
        # æå–å„ç±»å»ºè®®
        normal_suggestions = counterfactual_results.get('normal_tissue_suggestions', [])
        milder_suggestions = counterfactual_results.get('milder_suggestions', [])
        other_suggestions = counterfactual_results.get('other_suggestions', [])
        
        # å›¾1: æ­£å¸¸ç»„ç»‡æ¢å¤ç­–ç•¥ï¼ˆå¦‚æœæœ‰ï¼‰
        ax1 = axes[0, 0]
        if normal_suggestions:
            plot_suggestion_chart(ax1, normal_suggestions[:3], "æ¢å¤æ­£å¸¸ç»„ç»‡ç­–ç•¥", font_settings)
        else:
            ax1.text(0.5, 0.5, 'âš ï¸ æœªæ‰¾åˆ°ç›´æ¥æ¢å¤ä¸º\næ­£å¸¸ç»„ç»‡çš„ç­–ç•¥', 
                     ha='center', va='center', transform=ax1.transAxes,
                     fontsize=font_settings['label_font']['size'],
                     fontfamily=font_settings['label_font']['family'])
            ax1.set_title('æ¢å¤æ­£å¸¸ç»„ç»‡ç­–ç•¥', fontsize=font_settings['title_font']['size'], fontweight='bold',
                         fontfamily=font_settings['title_font']['family'])
        
        # å›¾2: è½»åº¦çƒ§ä¼¤æ”¹å–„ç­–ç•¥
        ax2 = axes[0, 1]
        if milder_suggestions:
            plot_suggestion_chart(ax2, milder_suggestions[:3], "æ”¹å–„ä¸ºæ›´è½»åº¦çƒ§ä¼¤ç­–ç•¥", font_settings)
        else:
            ax2.text(0.5, 0.5, 'âš ï¸ æœªæ‰¾åˆ°æ”¹å–„ä¸º\næ›´è½»åº¦çƒ§ä¼¤çš„ç­–ç•¥', 
                     ha='center', va='center', transform=ax2.transAxes,
                     fontsize=font_settings['label_font']['size'],
                     fontfamily=font_settings['label_font']['family'])
            ax2.set_title('æ”¹å–„ä¸ºæ›´è½»åº¦çƒ§ä¼¤ç­–ç•¥', fontsize=font_settings['title_font']['size'], fontweight='bold',
                         fontfamily=font_settings['title_font']['family'])
        
        # å›¾3: å…¶ä»–å˜åŒ–ç­–ç•¥
        ax3 = axes[1, 0]
        if other_suggestions:
            plot_suggestion_chart(ax3, other_suggestions[:3], "å…¶ä»–å˜åŒ–ç­–ç•¥", font_settings)
        else:
            ax3.text(0.5, 0.5, 'âš ï¸ æœªæ‰¾åˆ°å…¶ä»–\nå¯è¡Œå˜åŒ–ç­–ç•¥', 
                     ha='center', va='center', transform=ax3.transAxes,
                     fontsize=font_settings['label_font']['size'],
                     fontfamily=font_settings['label_font']['family'])
            ax3.set_title('å…¶ä»–å˜åŒ–ç­–ç•¥', fontsize=font_settings['title_font']['size'], fontweight='bold',
                         fontfamily=font_settings['title_font']['family'])
        
        # å›¾4: æ”¹å–„ç¨‹åº¦æ€»ç»“
        ax4 = axes[1, 1]
        plot_improvement_summary(ax4, normal_suggestions, milder_suggestions, 
                               counterfactual_results['original_prediction'], burn_type_mapping, font_settings)
        
        apply_chart_font_settings(ax1)
        apply_chart_font_settings(ax2)
        apply_chart_font_settings(ax3)
        apply_chart_font_settings(ax4, xlabel='ç­–ç•¥ç±»å‹', ylabel='æ”¹å–„ç¨‹åº¦')
        
        plt.tight_layout()
        return fig
        
    except Exception as e:
        st.warning(f"åäº‹å®å›¾è¡¨ç»˜åˆ¶é”™è¯¯: {str(e)}")
        return create_error_plot(str(e), font_settings)

def plot_suggestion_chart(ax, suggestions, title, font_settings):
    """ç»˜åˆ¶å»ºè®®å›¾è¡¨"""
    if not suggestions:
        return
    
    features = [s['feature'] for s in suggestions]
    efficiencies = [s.get('efficiency', s.get('confidence', 0)) for s in suggestions]
    confidences = [s.get('confidence', 0) for s in suggestions]
    targets = [s.get('target_name', 'æœªçŸ¥') for s in suggestions]
    
    y_pos = np.arange(len(features))
    colors = plt.cm.viridis(np.linspace(0, 1, len(features)))
    
    bars = ax.barh(y_pos, efficiencies, color=colors, alpha=0.8, height=0.6)
    ax.set_yticks(y_pos)
    
    # åˆ›å»ºæ ‡ç­¾ï¼šç‰¹å¾ + ç›®æ ‡
    labels = []
    for feat, target in zip(features, targets):
        labels.append(f"{feat}\nâ†’ {target}")
    
    ax.set_yticklabels(labels, fontfamily=font_settings['tick_font']['family'])
    ax.invert_yaxis()
    ax.set_xlabel('ç»¼åˆæ•ˆç‡', fontweight='bold',
                  fontfamily=font_settings['axis_font']['family'],
                  fontsize=font_settings['axis_font']['size'])
    ax.set_title(title, fontsize=font_settings['title_font']['size'], fontweight='bold',
                 fontfamily=font_settings['title_font']['family'])
    ax.set_xlim(0, 1.1)
    ax.grid(True, alpha=0.3, axis='x')
    
    for i, (bar, eff, conf, target) in enumerate(zip(bars, efficiencies, confidences, targets)):
        width = bar.get_width()
        ax.text(width + 0.02, bar.get_y() + bar.get_height()/2, 
                f'æ•ˆç‡: {eff:.3f}\nç½®ä¿¡åº¦: {conf:.1%}', 
                ha='left', va='center', fontweight='bold', 
                fontsize=font_settings['label_font']['size'] - 1,
                fontfamily=font_settings['label_font']['family'])

def plot_improvement_summary(ax, normal_suggestions, milder_suggestions, original_class, burn_type_mapping, font_settings):
    """ç»˜åˆ¶æ”¹å–„ç¨‹åº¦æ€»ç»“å›¾"""
    categories = ['æ¢å¤æ­£å¸¸ç»„ç»‡', 'æ”¹å–„ä¸ºè½»åº¦çƒ§ä¼¤', 'å…¶ä»–å˜åŒ–']
    
    # è®¡ç®—å¹³å‡æ”¹å–„ç¨‹åº¦
    avg_normal_improvement = np.mean([s.get('improvement', 0) for s in normal_suggestions]) if normal_suggestions else 0
    avg_milder_improvement = np.mean([s.get('improvement', 0) for s in milder_suggestions]) if milder_suggestions else 0
    avg_other_improvement = 0  # å…¶ä»–å˜åŒ–å‡è®¾ä¸º0
    
    improvements = [avg_normal_improvement, avg_milder_improvement, avg_other_improvement]
    colors = ['#4CAF50', '#FF9800', '#9E9E9E']
    
    x_pos = np.arange(len(categories))
    bars = ax.bar(x_pos, improvements, color=colors, alpha=0.8, width=0.6)
    
    ax.set_xlabel('ç­–ç•¥ç±»å‹', fontweight='bold',
                  fontfamily=font_settings['axis_font']['family'],
                  fontsize=font_settings['axis_font']['size'])
    ax.set_ylabel('å¹³å‡æ”¹å–„ç¨‹åº¦', fontweight='bold',
                  fontfamily=font_settings['axis_font']['family'],
                  fontsize=font_settings['axis_font']['size'])
    ax.set_title('ç­–ç•¥æ”¹å–„ç¨‹åº¦æ€»ç»“', fontsize=font_settings['title_font']['size'], fontweight='bold',
                 fontfamily=font_settings['title_font']['family'])
    ax.set_xticks(x_pos)
    ax.set_xticklabels(categories, rotation=45, fontfamily=font_settings['tick_font']['family'])
    ax.set_ylim(0, 110)
    ax.grid(True, alpha=0.3, axis='y')
    
    for bar, imp in zip(bars, improvements):
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width()/2., height + 2,
                f'{imp:.0f}åˆ†', ha='center', va='bottom',
                fontsize=font_settings['label_font']['size'], fontweight='bold',
                fontfamily=font_settings['label_font']['family'])
    
    # æ·»åŠ å½“å‰çŠ¶æ€
    ax.text(0.5, -0.2, f'å½“å‰çŠ¶æ€: {burn_type_mapping[original_class]["cn"]}',
            transform=ax.transAxes, ha='center', 
            fontsize=font_settings['label_font']['size'],
            fontfamily=font_settings['label_font']['family'],
            bbox=dict(boxstyle='round,pad=0.3', facecolor='lightblue', alpha=0.3))

def create_no_results_plot(message):
    """åˆ›å»ºæ— ç»“æœæ¶ˆæ¯å›¾"""
    font_settings = get_chart_font_settings()
    fig, ax = plt.subplots(figsize=(8, 4))
    ax.axis('off')
    ax.text(0.5, 0.6, 'âš ï¸ æ— åäº‹å®åˆ†æç»“æœ', 
            ha='center', va='center', fontsize=font_settings['title_font']['size'],
            fontweight='bold', color='#FF9800',
            fontfamily=font_settings['title_font']['family'])
    ax.text(0.5, 0.4, message,
            ha='center', va='center', fontsize=font_settings['label_font']['size'],
            fontfamily=font_settings['label_font']['family'])
    return fig

def create_error_plot(error_msg, font_settings):
    """åˆ›å»ºé”™è¯¯æ¶ˆæ¯å›¾"""
    fig, ax = plt.subplots(figsize=(8, 4))
    ax.axis('off')
    ax.text(0.5, 0.6, 'âŒ å›¾è¡¨ç»˜åˆ¶é”™è¯¯', 
            ha='center', va='center', fontsize=font_settings['title_font']['size'],
            fontweight='bold', color='#F44336',
            fontfamily=font_settings['title_font']['family'])
    ax.text(0.5, 0.4, error_msg[:50] + '...' if len(error_msg) > 50 else error_msg,
            ha='center', va='center', fontsize=font_settings['label_font']['size'],
            fontfamily=font_settings['label_font']['family'])
    return fig


# ç”ŸæˆåŒ»ç–—æ£€æµ‹æŠ¥å‘Šçš„å‡½æ•° - ä¿®æ”¹1ï¼šå¢å¼ºæŠ¥å‘Šå†…å®¹
def generate_medical_report(input_data, prediction, probabilities, shap_results, graph_results, counterfactual_results, burn_type_mapping, feature_names, language='ä¸­æ–‡'):
    """ç”Ÿæˆè¯¦ç»†çš„åŒ»ç–—æ£€æµ‹æŠ¥å‘Š"""
    
    burn_info = burn_type_mapping[prediction]
    
    if language == 'ä¸­æ–‡':
        report = f"""çƒ§ä¼¤æ™ºèƒ½è¯†åˆ«ç³»ç»Ÿ - åŒ»ç–—æ£€æµ‹æŠ¥å‘Š
==================================================

ç”Ÿæˆæ—¶é—´: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}

ã€åŸºæœ¬ä¿¡æ¯ã€‘
æ‚£è€…æ ·æœ¬ç¼–å·: {pd.Timestamp.now().strftime('%Y%m%d%H%M%S')}
åˆ†ææ¨¡å‹: éšæœºæ£®æ—å¤šåˆ†ç±»æ¨¡å‹
æ•°æ®ç²¾åº¦: å°æ•°ç‚¹å10ä½

ã€è¾“å…¥å‚æ•°è¯¦ç»†æ•°æ®ã€‘
BG1 (ç”Ÿç‰©æ ‡å¿—ç‰©1): {input_data.iloc[0, 0]:.10f}
IL-1Î² (ç™½ç»†èƒä»‹ç´ -1Î²): {input_data.iloc[0, 1]:.10f} pg/mL
EGF (è¡¨çš®ç”Ÿé•¿å› å­): {input_data.iloc[0, 2]:.10f} pg/mL
BG2 (ç”Ÿç‰©æ ‡å¿—ç‰©2): {input_data.iloc[0, 3]:.10f}

ã€è¯Šæ–­ç»“æœã€‘
ä¸»è¦è¯Šæ–­: {burn_info['cn']} ({burn_info['en']})
ç½®ä¿¡åº¦: {probabilities[prediction]:.2%}
ä¸´åºŠæè¿°: {burn_info['description']}

ã€æ¦‚ç‡åˆ†å¸ƒåˆ†æã€‘
"""
        for i, prob in enumerate(probabilities):
            report += f"{burn_type_mapping[i]['cn']}: {prob:.2%}\n"
        
        report += f"\nã€ç”Ÿç‰©æ ‡å¿—ç‰©ä¸´åºŠæ„ä¹‰åˆ†æã€‘\n"
        report += "="*50 + "\n"
        
        # åŸºäºSHAPå€¼çš„ä¸´åºŠåˆ†æ
        if shap_results:
            shap_values = shap_results['shap_values']
            for i, feature in enumerate(feature_names):
                shap_val = shap_values[i]
                original_val = input_data.iloc[0, i]
                
                report += f"\n{feature}åˆ†æ:\n"
                report += f"- å½“å‰æ°´å¹³: {original_val:.10f}\n"
                report += f"- å¯¹è¯Šæ–­å½±å“: {shap_val:+.6f} "
                
                if shap_val > 0.01:
                    report += "(æ˜¾è‘—æ­£å‘å½±å“ â†’ ä¿ƒè¿›è¯¥è¯Šæ–­)\n"
                elif shap_val < -0.01:
                    report += "(æ˜¾è‘—è´Ÿå‘å½±å“ â†’ æŠ‘åˆ¶è¯¥è¯Šæ–­)\n"
                else:
                    report += "(å½±å“è¾ƒå°)\n"
                
                # é’ˆå¯¹æ¯ä¸ªç‰¹å¾çš„ä¸´åºŠè§£é‡Š
                if feature == "IL-1Î²":
                    if original_val > 500:
                        report += "- ä¸´åºŠæ„ä¹‰: IL-1Î²æ°´å¹³æ˜¾è‘—å‡é«˜ï¼Œè¡¨æ˜å¼ºçƒˆçš„ç‚ç—‡ååº”ï¼Œå¯èƒ½ä¸ä¸¥é‡çƒ§ä¼¤ç›¸å…³\n"
                        report += "- æ²»ç–—å»ºè®®: éœ€è¦ç§¯ææŠ—ç‚æ²»ç–—ï¼Œç›‘æµ‹å…¨èº«ç‚ç—‡ååº”ç»¼åˆå¾\n"
                        report += "- æ—¥å¸¸æ³¨æ„: é¿å…æ„ŸæŸ“ï¼Œä¿æŒä¼¤å£æ¸…æ´ï¼Œå®šæœŸç›‘æµ‹ç‚ç—‡æŒ‡æ ‡\n"
                    elif original_val > 300:
                        report += "- ä¸´åºŠæ„ä¹‰: IL-1Î²æ°´å¹³ä¸­åº¦å‡é«˜ï¼Œæç¤ºä¸­åº¦ç‚ç—‡çŠ¶æ€\n"
                        report += "- æ²»ç–—å»ºè®®: é€‚å½“æŠ—ç‚æ²»ç–—ï¼Œå¯†åˆ‡è§‚å¯Ÿç—…æƒ…å˜åŒ–\n"
                        report += "- æ—¥å¸¸æ³¨æ„: æ³¨æ„ä¼¤å£æŠ¤ç†ï¼Œé¿å…åˆºæ¿€æ€§ç‰©è´¨æ¥è§¦\n"
                    else:
                        report += "- ä¸´åºŠæ„ä¹‰: IL-1Î²æ°´å¹³åœ¨æ­£å¸¸èŒƒå›´å†…\n"
                        report += "- æ²»ç–—å»ºè®®: ç»´æŒå½“å‰æ²»ç–—æ–¹æ¡ˆ\n"
                        report += "- æ—¥å¸¸æ³¨æ„: ç»§ç»­ä¿æŒè‰¯å¥½çš„ä¼¤å£æŠ¤ç†ä¹ æƒ¯\n"
                        
                elif feature == "EGF":
                    if original_val < 400:
                        report += "- ä¸´åºŠæ„ä¹‰: EGFæ°´å¹³åä½ï¼Œå¯èƒ½å½±å“ä¼¤å£æ„ˆåˆèƒ½åŠ›\n"
                        report += "- æ²»ç–—å»ºè®®: è€ƒè™‘å¤–æºæ€§EGFè¡¥å……æ²»ç–—\n"
                        report += "- æ—¥å¸¸æ³¨æ„: åŠ å¼ºè¥å…»æ”¯æŒï¼Œä¿ƒè¿›å†…æºæ€§EGFç”Ÿæˆ\n"
                    elif original_val > 600:
                        report += "- ä¸´åºŠæ„ä¹‰: EGFæ°´å¹³è¾ƒé«˜ï¼Œæœ‰åˆ©äºç»„ç»‡ä¿®å¤\n"
                        report += "- æ²»ç–—å»ºè®®: ç»´æŒè‰¯å¥½çš„æ„ˆåˆç¯å¢ƒ\n"
                        report += "- æ—¥å¸¸æ³¨æ„: ç»§ç»­ä¿æŒæœ‰åˆ©äºä¼¤å£æ„ˆåˆçš„ç”Ÿæ´»æ–¹å¼\n"
                    else:
                        report += "- ä¸´åºŠæ„ä¹‰: EGFæ°´å¹³åœ¨æ­£å¸¸èŒƒå›´å†…\n"
                        report += "- æ²»ç–—å»ºè®®: å½“å‰EGFæ°´å¹³é€‚å®œä¼¤å£æ„ˆåˆ\n"
                        report += "- æ—¥å¸¸æ³¨æ„: ä¿æŒå‡è¡¡è¥å…»ï¼Œä¿ƒè¿›æ­£å¸¸æ„ˆåˆ\n"
                        
                elif feature == "BG1":
                    if abs(original_val) > 3:
                        report += "- ä¸´åºŠæ„ä¹‰: BG1æ°´å¹³å¼‚å¸¸ï¼Œå¯èƒ½æŒ‡ç¤ºç»„ç»‡æŸä¼¤\n"
                        report += "- æ²»ç–—å»ºè®®: è¿›ä¸€æ­¥è¯„ä¼°ç»„ç»‡æŸä¼¤ç¨‹åº¦\n"
                        report += "- æ—¥å¸¸æ³¨æ„: é¿å…è¿›ä¸€æ­¥ç»„ç»‡æŸä¼¤ï¼Œæ³¨æ„ä¿æŠ¤åˆ›é¢\n"
                    else:
                        report += "- ä¸´åºŠæ„ä¹‰: BG1æ°´å¹³åœ¨å‚è€ƒèŒƒå›´å†…\n"
                        report += "- æ²»ç–—å»ºè®®: ç»§ç»­å½“å‰æ²»ç–—\n"
                        report += "- æ—¥å¸¸æ³¨æ„: å®šæœŸç›‘æµ‹ç”Ÿç‰©æ ‡å¿—ç‰©å˜åŒ–\n"
                        
                elif feature == "BG2":
                    if original_val < -0.5:
                        report += "- ä¸´åºŠæ„ä¹‰: BG2æ°´å¹³æ˜¾è‘—åä½ï¼Œæç¤ºä¿®å¤èƒ½åŠ›å—æŸ\n"
                        report += "- æ²»ç–—å»ºè®®: åŠ å¼ºä¿®å¤æ”¯æŒæ²»ç–—\n"
                        report += "- æ—¥å¸¸æ³¨æ„: æ³¨æ„è¥å…»è¡¥å……ï¼Œä¿ƒè¿›ä¿®å¤èƒ½åŠ›æ¢å¤\n"
                    elif original_val > 0.5:
                        report += "- ä¸´åºŠæ„ä¹‰: BG2æ°´å¹³åé«˜ï¼Œå¯èƒ½åæ˜ ä»£å¿æ€§ä¿®å¤\n"
                        report += "- æ²»ç–—å»ºè®®: è§‚å¯Ÿä¿®å¤è¿›å±•ï¼Œé€‚æ—¶è°ƒæ•´æ²»ç–—\n"
                        report += "- æ—¥å¸¸æ³¨æ„: ç»´æŒé€‚åº¦çš„ä¿®å¤ç¯å¢ƒ\n"
                    else:
                        report += "- ä¸´åºŠæ„ä¹‰: BG2æ°´å¹³åœ¨æ­£å¸¸æ³¢åŠ¨èŒƒå›´å†…\n"
                        report += "- æ²»ç–—å»ºè®®: å½“å‰ä¿®å¤çŠ¶æ€è‰¯å¥½\n"
                        report += "- æ—¥å¸¸æ³¨æ„: ç»§ç»­ä¿æŒæœ‰åˆ©äºä¿®å¤çš„ç”Ÿæ´»æ–¹å¼\n"
        
        # SHAPåˆ†æç»“æœ
        if shap_results:
            report += f"\nã€SHAPå¯è§£é‡Šæ€§åˆ†æã€‘\n"
            report += "="*50 + "\n"
            report += "ç‰¹å¾é‡è¦æ€§æ’åº (åŸºäºSHAPç»å¯¹å€¼):\n"
            for i, (feature, importance) in enumerate(zip(shap_results['sorted_features'], shap_results['sorted_importance'])):
                report += f"{i+1}. {feature}: {importance:.10f}\n"
            # æ–°å¢ï¼šSHAPå›¾è¡¨åˆ†ææè¿°
            report += f"\nã€SHAPå›¾è¡¨åˆ†æè§£è¯»ã€‘\n"
            report += "å¤šç±»åˆ«SHAPåˆ†æå›¾æ˜¾ç¤ºæ‰€æœ‰å…­ç§çƒ§ä¼¤ç±»å‹çš„ç‰¹å¾å½±å“æ¨¡å¼ï¼š\n"
            report += "- çº¢è‰²æ¡å½¢è¡¨ç¤ºç‰¹å¾å¯¹å½“å‰è¯Šæ–­æœ‰æ­£å‘ä¿ƒè¿›ä½œç”¨\n"
            report += "- è“è‰²æ¡å½¢è¡¨ç¤ºç‰¹å¾å¯¹å½“å‰è¯Šæ–­æœ‰è´Ÿå‘æŠ‘åˆ¶ä½œç”¨\n"
            report += "- æ•£ç‚¹å¤§å°åæ˜ ç‰¹å¾é‡è¦æ€§ç»å¯¹å€¼å¤§å°\n"
            report += f"- å½“å‰è¯Šæ–­ç±»åˆ«({burn_info['cn']})ç”¨çº¢è‰²è¾¹æ¡†é«˜äº®æ˜¾ç¤º\n"
            report += f"- æœ€é‡è¦çš„ç‰¹å¾: {shap_results['sorted_features'][0]} (SHAPå€¼: {shap_results['sorted_importance'][0]:.6f})\n"
        
        # å›¾ç½‘ç»œåˆ†æç»“æœ
        if graph_results:
            report += f"\nã€å›¾ç½‘ç»œåˆ†æç»“æœã€‘\n"
            report += "="*50 + "\n"
            report += f"ç½‘ç»œèŠ‚ç‚¹æ•°: {len(graph_results['graph'].nodes())}\n"
            report += f"ç½‘ç»œè¾¹æ•°: {len(graph_results['graph'].edges())}\n"
            report += "ç‰¹å¾ä¸­å¿ƒæ€§åˆ†æ:\n"
            for feature in graph_results['degree_centrality']:
                report += f"- {feature}: åº¦ä¸­å¿ƒæ€§={graph_results['degree_centrality'][feature]:.6f}, ä»‹æ•°ä¸­å¿ƒæ€§={graph_results['betweenness_centrality'][feature]:.6f}, ç´§å¯†ä¸­å¿ƒæ€§={graph_results['closeness_centrality'][feature]:.6f}\n"
            
            # æ–°å¢ï¼šå›¾ç½‘ç»œå›¾è¡¨åˆ†ææè¿°
            report += f"\nã€å›¾ç½‘ç»œå›¾è¡¨åˆ†æè§£è¯»ã€‘\n"
            report += "ç‰¹å¾å…³è”ç½‘ç»œå›¾æ­ç¤ºç”Ÿç‰©æ ‡å¿—ç‰©é—´çš„ç›¸äº’ä½œç”¨å…³ç³»ï¼š\n"
            report += "- èŠ‚ç‚¹å¤§å°åæ˜ ç‰¹å¾åœ¨é¢„æµ‹ä¸­çš„ç›¸å¯¹é‡è¦æ€§\n"
            report += "- è¾¹ç²—ç»†è¡¨ç¤ºç‰¹å¾é—´ç›¸å…³æ€§å¼ºåº¦\n"
            report += "- åº¦ä¸­å¿ƒæ€§é«˜çš„ç‰¹å¾åœ¨ç½‘ç»œä¸­è¿æ¥æ›´å¹¿æ³›\n"
            report += "- ä»‹æ•°ä¸­å¿ƒæ€§é«˜çš„ç‰¹å¾åœ¨ç½‘ç»œä¸­èµ·æ¡¥æ¢ä½œç”¨\n"
            report += "- é›·è¾¾å›¾å±•ç¤ºä¸åŒä¸­å¿ƒæ€§æŒ‡æ ‡çš„å¯¹æ¯”åˆ†æ\n"
            report += "- çƒ­åŠ›å›¾ç›´è§‚æ˜¾ç¤ºç‰¹å¾é—´çš„æ•°å€¼ç›¸å…³æ€§\n"
            
            # åˆ†æç½‘ç»œç»“æ„ç‰¹ç‚¹
            max_degree_feature = max(graph_results['degree_centrality'], key=graph_results['degree_centrality'].get)
            max_betweenness_feature = max(graph_results['betweenness_centrality'], key=graph_results['betweenness_centrality'].get)
            report += f"- ç½‘ç»œæ¢çº½ç‰¹å¾: {max_degree_feature} (è¿æ¥æœ€å¹¿æ³›)\n"
            report += f"- å…³é”®æ¡¥æ¢ç‰¹å¾: {max_betweenness_feature} (ä¿¡æ¯ä¼ é€’å…³é”®èŠ‚ç‚¹)\n"
        
        # åäº‹å®åˆ†æç»“æœ - ä¿®æ”¹åçš„åˆ¤æ–­æ¡ä»¶
        if (counterfactual_results and 
            not counterfactual_results.get('skip_analysis', False) and
            (counterfactual_results.get('has_normal_tissue_suggestions', False) or
             counterfactual_results.get('normal_tissue_suggestions', []))):
            
            suggestions = counterfactual_results.get('normal_tissue_suggestions', [])
            if suggestions:
                report += f"\nã€åäº‹å®åˆ†æä¸æ²»ç–—å»ºè®®ã€‘\n"
                report += "="*50 + "\n"
                report += "åŸºäºæ¨¡å‹é¢„æµ‹çš„å¹²é¢„ç­–ç•¥åˆ†æ:\n\n"
                
                for i, suggestion in enumerate(suggestions[:3], 1):
                    report += f"æ²»ç–—æ–¹æ¡ˆ {i}:\n"
                    report += f"- è°ƒæ•´ç›®æ ‡: å°†{suggestion.get('feature', 'æœªçŸ¥ç‰¹å¾')}{suggestion.get('direction', 'è°ƒæ•´')}åˆ°åŸæ¥çš„ {suggestion.get('change_factor', 1.0):.1f}å€\n"
                    report += f"- å…·ä½“æ•°å€¼: {suggestion.get('original_value', 0):.10f} â†’ {suggestion.get('new_value', 0):.10f}\n"
                    report += f"- é¢„æœŸæ•ˆæœç½®ä¿¡åº¦: {suggestion.get('confidence', 0):.2%}\n"
                    report += f"- ä¸´åºŠæ„ä¹‰: é¢„æµ‹ä»{burn_type_mapping[counterfactual_results.get('original_prediction', 0)]['cn']}æ”¹å–„åˆ°{burn_type_mapping[suggestion.get('target_class', 0)]['cn']}\n\n"
                
                # æ–°å¢ï¼šåäº‹å®å›¾è¡¨åˆ†ææè¿°
                report += f"\nã€åäº‹å®å›¾è¡¨åˆ†æè§£è¯»ã€‘\n"
                report += "åäº‹å®åˆ†æå›¾å±•ç¤ºç‰¹å¾è°ƒæ•´å¯¹è¯Šæ–­ç»“æœçš„å½±å“ï¼š\n"
                report += "- å·¦ä¾§æ¡å½¢å›¾æ˜¾ç¤ºä¸åŒè°ƒæ•´æ–¹æ¡ˆçš„é¢„æœŸç½®ä¿¡åº¦\n"
                report += "- ç»¿è‰²è¡¨ç¤ºå¢åŠ ç‰¹å¾å€¼ï¼Œçº¢è‰²è¡¨ç¤ºå‡å°‘ç‰¹å¾å€¼\n"
                report += "- å³ä¾§è·¯å¾„å›¾å¯¹æ¯”å½“å‰å€¼ä¸ç›®æ ‡å€¼çš„å·®å¼‚\n"
                report += "- ç®­å¤´æ–¹å‘æŒ‡ç¤ºç‰¹å¾è°ƒæ•´çš„æ–¹å‘å’Œå¹…åº¦\n"
                if suggestions:
                    report += f"- æœ€ä¼˜è°ƒæ•´æ–¹æ¡ˆ: {suggestions[0].get('feature', 'æœªçŸ¥ç‰¹å¾')} ({suggestions[0].get('direction', 'è°ƒæ•´')}{suggestions[0].get('change_factor', 1.0):.1f}å€)\n"
                    
        # æ²»ç–—å’Œæ³¨æ„äº‹é¡¹
        report += f"\nã€ä¸´åºŠæ²»ç–—å»ºè®®ä¸æ³¨æ„äº‹é¡¹ã€‘\n"
        report += "="*50 + "\n"
        
        if prediction == 0:
            report += "å½“å‰è¯Šæ–­ä¸ºæ­£å¸¸ç»„ç»‡ï¼Œæ— éœ€ç‰¹æ®Šæ²»ç–—ã€‚\n"
            report += "å»ºè®®:\n"
            report += "- å®šæœŸç›‘æµ‹ç”Ÿç‰©æ ‡å¿—ç‰©æ°´å¹³\n"
            report += "- ä¿æŒå¥åº·ç”Ÿæ´»æ–¹å¼\n"
            report += "- é¿å…çƒ§ä¼¤é£é™©å› ç´ \n"
        else:
            report += f"é’ˆå¯¹{burn_info['cn']}çš„æ²»ç–—å»ºè®®:\n"
            
            if prediction in [1, 2]:  # æµ…è¡¨å’Œæ·±éƒ¨éƒ¨åˆ†åšåº¦çƒ§ä¼¤
                report += "- ç«‹å³è¿›è¡Œä¼¤å£æ¸…æ´å’Œæ¶ˆæ¯’\n"
                report += "- ä½¿ç”¨é€‚å½“çš„æ•·æ–™ä¿æŠ¤åˆ›é¢\n"
                report += "- è€ƒè™‘ä½¿ç”¨ç”Ÿé•¿å› å­ä¿ƒè¿›æ„ˆåˆ\n"
                report += "- å®šæœŸæ›´æ¢æ•·æ–™ï¼Œç›‘æµ‹æ„ŸæŸ“è¿¹è±¡\n"
                report += "- å¦‚IL-1Î²æ°´å¹³é«˜ï¼Œè€ƒè™‘æŠ—ç‚æ²»ç–—\n"
                
            elif prediction == 3:  # å…¨å±‚åšåº¦çƒ§ä¼¤
                report += "- éœ€è¦å¤–ç§‘æ¸…åˆ›å’Œæ¤çš®æ‰‹æœ¯\n"
                report += "- å…¨èº«æŠ—æ„ŸæŸ“æ²»ç–—\n"
                report += "- è¥å…»æ”¯æŒï¼Œä¿ƒè¿›ç»„ç»‡ä¿®å¤\n"
                report += "- ç–¼ç—›ç®¡ç†å’Œç‚ç—‡æ§åˆ¶\n"
                report += "- é•¿æœŸåº·å¤å’ŒåŠŸèƒ½è®­ç»ƒ\n"
                
            elif prediction == 4:  # ç”µå‡»çƒ§ä¼¤
                report += "- è¯„ä¼°æ·±éƒ¨ç»„ç»‡æŸä¼¤ç¨‹åº¦\n"
                report += "- ç›‘æµ‹å¿ƒç”µå›¾å’Œè‚Œé…¸æ¿€é…¶\n"
                report += "- ç§¯ææ¸…åˆ›ï¼Œé¢„é˜²æ„ŸæŸ“\n"
                report += "- æ³¨æ„å¯èƒ½çš„å¹¶å‘ç—‡\n"
                report += "- å¤šå­¦ç§‘å›¢é˜Ÿåä½œæ²»ç–—\n"
                
            elif prediction == 5:  # ç«ç„°çƒ§ä¼¤
                report += "- è¯„ä¼°å¸å…¥æ€§æŸä¼¤é£é™©\n"
                report += "- å…¨é¢æ¸…åˆ›å’Œçƒ§ä¼¤æŠ¤ç†\n"
                report += "- é¢„é˜²æ„ŸæŸ“å’Œè´¥è¡€ç—‡\n"
                report += "- è¥å…»æ”¯æŒå’Œä»£è°¢ç®¡ç†\n"
                report += "- å¿ƒç†æ”¯æŒå’Œåº·å¤æ²»ç–—\n"
            
            report += "\næ—¥å¸¸æ³¨æ„äº‹é¡¹:\n"
            report += "- ä¸¥æ ¼éµåŒ»å˜±è¿›è¡Œæ²»ç–—\n"
            report += "- å®šæœŸå¤æŸ¥ç”Ÿç‰©æ ‡å¿—ç‰©\n"
            report += "- æ³¨æ„ä¼¤å£æŠ¤ç†å’Œä¸ªäººå«ç”Ÿ\n"
            report += "- åˆç†è¥å…»ï¼Œä¿ƒè¿›æ„ˆåˆ\n"
            report += "- é¿å…åˆºæ¿€æ€§ç‰©è´¨æ¥è§¦åˆ›é¢\n"
        
        report += f"\nã€æŠ¥å‘Šè¯´æ˜ã€‘\n"
        report += "="*50 + "\n"
        report += "1. æœ¬æŠ¥å‘ŠåŸºäºæœºå™¨å­¦ä¹ æ¨¡å‹åˆ†æç”Ÿæˆï¼Œä»…ä¾›å‚è€ƒ\n"
        report += "2. ä¸´åºŠè¯Šæ–­éœ€ç»“åˆä¸´åºŠè¡¨ç°å’ŒåŒ»å¸ˆåˆ¤æ–­\n"
        report += "3. æ²»ç–—å»ºè®®éœ€åœ¨ä¸“ä¸šåŒ»å¸ˆæŒ‡å¯¼ä¸‹å®æ–½\n"
        report += "4. å®šæœŸéšè®¿å’Œç›‘æµ‹å¯¹æ²»ç–—æ•ˆæœè‡³å…³é‡è¦\n"
        
    else:  # English version
        report = f"""Burn Intelligent Recognition System - Medical Analysis Report
==================================================

Generated: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}

ã€Basic Informationã€‘
Sample ID: {pd.Timestamp.now().strftime('%Y%m%d%H%M%S')}
Analysis Model: Random Forest Multi-class Model
Data Precision: 10 decimal places

ã€Input Parametersã€‘
BG1 (Biomarker 1): {input_data.iloc[0, 0]:.10f}
IL-1Î² (Interleukin-1Î²): {input_data.iloc[0, 1]:.10f} pg/mL
EGF (Epidermal Growth Factor): {input_data.iloc[0, 2]:.10f} pg/mL
BG2 (Biomarker 2): {input_data.iloc[0, 3]:.10f}

ã€Diagnosis Resultsã€‘
Primary Diagnosis: {burn_info['en']} ({burn_info['cn']})
Confidence: {probabilities[prediction]:.2%}
Clinical Description: {burn_info['description_en']}

ã€Probability Distribution Analysisã€‘
"""
        for i, prob in enumerate(probabilities):
            report += f"{burn_type_mapping[i]['en']}: {prob:.2%}\n"
    
    return report

# è‡ªåŠ¨åŠ è½½æ¨¡å‹
if 'model' not in st.session_state:
    with st.spinner("æ­£åœ¨åŠ è½½æ¨¡å‹..."): st.session_state.model = load_model()

# çƒ§ä¼¤ç±»å‹æ˜ å°„
burn_type_mapping = {
    0: {"en": "Normal", "cn": "æ­£å¸¸ç»„ç»‡", "color": "#4CAF50", "description": "æ­£å¸¸çš®è‚¤ç»„ç»‡", "description_en": "Normal skin tissue"},
    1: {"en": "Superficial partial-thickness", "cn": "æµ…è¡¨éƒ¨åˆ†åšåº¦çƒ§ä¼¤", "color": "#FF9800", "description": "è¡¨çš®å’Œéƒ¨åˆ†çœŸçš®å—æŸ", "description_en": "Epidermis and partial dermis damage"},
    2: {"en": "Deep partial-thickness", "cn": "æ·±å±‚éƒ¨åˆ†åšåº¦çƒ§ä¼¤", "color": "#FF5722", "description": "çœŸçš®æ·±å±‚å—æŸ", "description_en": "Deep dermis damage"},
    3: {"en": "Full-thickness", "cn": "å…¨å±‚åšåº¦çƒ§ä¼¤", "color": "#F44336", "description": "çš®è‚¤å…¨å±‚å—æŸ", "description_en": "Full-thickness skin damage"},
    4: {"en": "Electrical", "cn": "ç”µå‡»çƒ§ä¼¤", "color": "#9C27B0", "description": "ç”µå‡»å¯¼è‡´çš„ç»„ç»‡æŸä¼¤", "description_en": "Tissue damage caused by electric shock"},
    5: {"en": "Flame", "cn": "ç«ç„°çƒ§ä¼¤", "color": "#795548", "description": "ç«ç„°ç›´æ¥æ¥è§¦å¯¼è‡´çš„çƒ§ä¼¤", "description_en": "Burn caused by direct flame contact"}
}

# åˆå§‹åŒ–session state
if 'language' not in st.session_state: st.session_state.language = 'ä¸­æ–‡'
if 'chart_colors' not in st.session_state: st.session_state.chart_colors = ['#4E79A7', '#F28E2B', '#E15759', '#76B7B2', '#59A14F', '#EDC948']
if 'title_font' not in st.session_state: st.session_state.title_font = {'family': 'Microsoft YaHei', 'size': 14, 'weight': 'bold'}
if 'label_font' not in st.session_state: st.session_state.label_font = {'family': 'Microsoft YaHei', 'size': 10}
if 'theme' not in st.session_state: st.session_state.theme = 'light'
if 'data_precision' not in st.session_state: st.session_state.data_precision = 10

# åˆå§‹åŒ–å›¾è¡¨å­—ä½“è®¾ç½®
if 'chart_title_font' not in st.session_state: 
    st.session_state.chart_title_font = {'family': 'Microsoft YaHei', 'size': 14, 'weight': 'bold'}
if 'chart_axis_font' not in st.session_state: 
    st.session_state.chart_axis_font = {'family': 'Microsoft YaHei', 'size': 10}
if 'chart_tick_font' not in st.session_state: 
    st.session_state.chart_tick_font = {'family': 'Microsoft YaHei', 'size': 8}
if 'chart_label_font' not in st.session_state: 
    st.session_state.chart_label_font = {'family': 'Microsoft YaHei', 'size': 9}

# ä¾§è¾¹æ 
with st.sidebar:
    st.image("https://img.icons8.com/color/96/000000/fire-element.png", width=80)
    st.title("çƒ§ä¼¤è¯†åˆ«ç³»ç»Ÿ")
    st.markdown("---")
    # ä¿®å¤ï¼šæ·»åŠ å”¯ä¸€çš„keyå‚æ•°
    app_mode = st.selectbox("é€‰æ‹©åº”ç”¨æ¨¡å¼", ["ğŸ”¬ çƒ§ä¼¤è¯†åˆ«åˆ†æ", "ğŸ“– ä½¿ç”¨æŒ‡å—", "âš™ï¸ ç³»ç»Ÿè®¾ç½®"], key="app_mode_select")
    st.markdown("---")
    if st.session_state.model is not None: st.success("âœ… æ¨¡å‹å·²åŠ è½½")
    else: st.error("âŒ æ¨¡å‹åŠ è½½å¤±è´¥")

# ä¸»é¡µé¢å†…å®¹
if app_mode == "ğŸ”¬ çƒ§ä¼¤è¯†åˆ«åˆ†æ":
    st.markdown('<div class="main-header">ğŸ”¥ çƒ§ä¼¤æ™ºèƒ½è¯†åˆ«ä¸åˆ†æç³»ç»Ÿ</div>', unsafe_allow_html=True)
    
    if st.session_state.model is not None:
        model = st.session_state.model
        st.success("âœ… ä¸“ä¸šæ¨¡å¼ - ä½¿ç”¨è®­ç»ƒå¥½çš„éšæœºæ£®æ—æ¨¡å‹")
    else:
        st.error("âŒ æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œæ— æ³•è¿›è¡Œåˆ†æ")
        st.stop()
    
    tab1, tab2 = st.tabs(["ğŸ” å•æ ·æœ¬åˆ†æ", "ğŸ“Š æ‰¹é‡åˆ†æ"])
    
    with tab1:
        col1, col2 = st.columns([2, 1])
        
        with col1:
            if st.session_state.language == 'ä¸­æ–‡':
                st.markdown('<div class="sub-header">ğŸ“‹ è¾“å…¥çƒ§ä¼¤ç‰¹å¾å‚æ•°</div>', unsafe_allow_html=True)
            else:
                st.markdown('<div class="sub-header">ğŸ“‹ Input Burn Characteristics</div>', unsafe_allow_html=True)
            
            with st.form("input_form"):
                col1_1, col1_2 = st.columns(2)
                with col1_1:
                    feature1 = st.number_input("BG1 ç”Ÿç‰©æ ‡å¿—ç‰©", value=-3.696319906, format="%.10f", help="ç¬¬ä¸€ä¸ªç”Ÿç‰©æ ‡å¿—ç‰©å‚æ•°")
                    feature2 = st.number_input("IL-1Î² (pg/mL)", value=387.7812826, format="%.10f", help="ç™½ç»†èƒä»‹ç´ -1Î²æµ“åº¦")
                with col1_2:
                    feature3 = st.number_input("EGF (pg/mL)", value=1060.934711, format="%.10f", help="è¡¨çš®ç”Ÿé•¿å› å­æµ“åº¦")
                    feature4 = st.number_input("BG2 ç”Ÿç‰©æ ‡å¿—ç‰©", value=-0.501551816, format="%.10f", help="ç¬¬äºŒä¸ªç”Ÿç‰©æ ‡å¿—ç‰©å‚æ•°")
                
                if st.session_state.language == 'ä¸­æ–‡':
                    advanced_analysis = st.checkbox("æ‰§è¡ŒSHAP+å›¾ç½‘ç»œ+åäº‹å®åˆ†æ", value=True, key="advanced_checkbox")
                    submitted = st.form_submit_button("ğŸš€ å¼€å§‹åˆ†æ", use_container_width=True)
                else:
                    advanced_analysis = st.checkbox("Perform SHAP+Graph+Counterfactual Analysis", value=True, key="advanced_checkbox_en")
                    submitted = st.form_submit_button("ğŸš€ Start Analysis", use_container_width=True)
        
        with col2:
            if st.session_state.language == 'ä¸­æ–‡':
                st.markdown('<div class="sub-header">ğŸ’¡ å‚æ•°è¯´æ˜</div>', unsafe_allow_html=True)
                st.markdown("""
                <div class="feature-box"><strong>BG1:</strong> å…³é”®ç”Ÿç‰©æ ‡å¿—ç‰©1ï¼Œåæ˜ ç»„ç»‡ç‚ç—‡çŠ¶æ€</div>
                <div class="feature-box"><strong>IL-1Î²:</strong> ç‚ç—‡å› å­ï¼Œæµ“åº¦ä¸çƒ§ä¼¤ä¸¥é‡ç¨‹åº¦ç›¸å…³</div>
                <div class="feature-box"><strong>EGF:</strong> è¡¨çš®ç”Ÿé•¿å› å­ï¼Œä¿ƒè¿›ä¼¤å£æ„ˆåˆ</div>
                <div class="feature-box"><strong>BG2:</strong> å…³é”®ç”Ÿç‰©æ ‡å¿—ç‰©2ï¼Œç»„ç»‡ä¿®å¤æŒ‡æ ‡</div>
                """, unsafe_allow_html=True)
            else:
                st.markdown('<div class="sub-header">ğŸ’¡ Parameter Description</div>', unsafe_allow_html=True)
                st.markdown("""
                <div class="feature-box"><strong>BG1:</strong> Key biomarker 1, reflects tissue inflammation status</div>
                <div class="feature-box"><strong>IL-1Î²:</strong> Inflammatory factor, concentration correlates with burn severity</div>
                <div class="feature-box"><strong>EGF:</strong> Epidermal growth factor, promotes wound healing</div>
                <div class="feature-box"><strong>BG2:</strong> Key biomarker 2, tissue repair indicator</div>
                """, unsafe_allow_html=True)
        
        if submitted:
            try:
                input_data = pd.DataFrame([[feature1, feature2, feature3, feature4]], columns=model.feature_names_in_)
                prediction = model.predict(input_data)[0]
                probabilities = model.predict_proba(input_data)[0]
                
                st.markdown("---")
                if st.session_state.language == 'ä¸­æ–‡':
                    st.markdown('<div class="sub-header">ğŸ“Š åˆ†æç»“æœ</div>', unsafe_allow_html=True)
                else:
                    st.markdown('<div class="sub-header">ğŸ“Š Analysis Results</div>', unsafe_allow_html=True)
                
                col_res1, col_res2, col_res3 = st.columns([1, 2, 1])
                with col_res2:
                    burn_info = burn_type_mapping[prediction]
                    if st.session_state.language == 'ä¸­æ–‡':
                        st.markdown(f"""
                        <div class="prediction-box">
                            <h3>è¯Šæ–­ç»“æœ: {burn_info['cn']}</h3>
                            <p><strong>è‹±æ–‡åç§°:</strong> {burn_info['en']}</p>
                            <p><strong>æè¿°:</strong> {burn_info['description']}</p>
                            <p><strong>ç½®ä¿¡åº¦:</strong> {probabilities[prediction]:.2%}</p>
                        </div>
                        """, unsafe_allow_html=True)
                    else:
                        st.markdown(f"""
                        <div class="prediction-box">
                            <h3>Diagnosis Result: {burn_info['en']}</h3>
                            <p><strong>Chinese Name:</strong> {burn_info['cn']}</p>
                            <p><strong>Description:</strong> {burn_info['description_en']}</p>
                            <p><strong>Confidence:</strong> {probabilities[prediction]:.2%}</p>
                        </div>
                        """, unsafe_allow_html=True)
                
                if advanced_analysis:
                    if st.session_state.language == 'ä¸­æ–‡':
                        st.markdown('<div class="sub-header">ğŸ”¬ é«˜çº§æ¨¡å‹åˆ†æ</div>', unsafe_allow_html=True)
                    else:
                        st.markdown('<div class="sub-header">ğŸ”¬ Advanced Model Analysis</div>', unsafe_allow_html=True)
                    
                    # SHAPåˆ†æ
                    with st.spinner("æ­£åœ¨è¿›è¡ŒSHAPåˆ†æ..." if st.session_state.language == 'ä¸­æ–‡' else "Performing SHAP analysis..."):
                        shap_results = perform_shap_analysis(model, input_data, model.feature_names_in_)
                    
                    # å›¾ç½‘ç»œåˆ†æ
                    with st.spinner("æ­£åœ¨è¿›è¡Œå›¾ç½‘ç»œåˆ†æ..." if st.session_state.language == 'ä¸­æ–‡' else "Performing graph network analysis..."):
                        graph_results = perform_graph_analysis([feature1, feature2, feature3, feature4], model.feature_names_in_, prediction, burn_type_mapping)
                    
                    # åœ¨è°ƒç”¨åäº‹å®åˆ†æä¹‹å‰æ·»åŠ è°ƒè¯•
                    st.write("ğŸ” è°ƒè¯•ä¿¡æ¯ï¼š")
                    st.write(f"SHAPç»“æœæ˜¯å¦ä¸ºç©º: {shap_results is not None}")
                    st.write(f"å›¾ç½‘ç»œç»“æœæ˜¯å¦ä¸ºç©º: {graph_results is not None}")
                    if shap_results:
                        st.write(f"SHAPå€¼: {shap_results.get('shap_values', [])}")
                    if graph_results:
                        st.write(f"å›¾ç½‘ç»œæœ‰{len(graph_results.get('graph', nx.Graph()).nodes())}ä¸ªèŠ‚ç‚¹")

                    # åäº‹å®åˆ†æ - ä¼ å…¥SHAPå’Œå›¾ç½‘ç»œç»“æœ
                    if prediction != 0:  # ä¸æ˜¯æ­£å¸¸ç»„ç»‡
                        with st.spinner("æ­£åœ¨è¿›è¡Œåäº‹å®åˆ†æ..." if st.session_state.language == 'ä¸­æ–‡' else "Performing counterfactual analysis..."):
                            counterfactual_results = perform_counterfactual_analysis(
                                model=model,
                                input_data=input_data,
                                original_prediction=prediction,
                                feature_names=model.feature_names_in_,
                                burn_type_mapping=burn_type_mapping,
                                shap_results=shap_results,  # å…³é”®ï¼šä¼ å…¥SHAPç»“æœ
                                graph_results=graph_results  # å…³é”®ï¼šä¼ å…¥å›¾ç½‘ç»œç»“æœ
                            )
                            
                            # æ·»åŠ è°ƒè¯•ä¿¡æ¯
                            st.write("ğŸ” åäº‹å®åˆ†æç»“æœ:")
                            st.write(f"æ˜¯å¦æœ‰æ­£å¸¸ç»„ç»‡å»ºè®®: {counterfactual_results.get('has_normal_tissue_suggestions', False)}")
                            st.write(f"æ­£å¸¸ç»„ç»‡å»ºè®®æ•°é‡: {len(counterfactual_results.get('normal_tissue_suggestions', []))}")
                            st.write(f"è½»åº¦çƒ§ä¼¤å»ºè®®æ•°é‡: {len(counterfactual_results.get('milder_suggestions', []))}")
                            st.write(f"æ‰€æœ‰å»ºè®®æ•°é‡: {len(counterfactual_results.get('all_counterfactuals', []))}")
                    else:
                        # æ­£å¸¸ç»„ç»‡ä¹Ÿéœ€è¦è°ƒç”¨åäº‹å®åˆ†æï¼Œä½†ä¼šè¿”å›ç»´æŒå»ºè®®
                        with st.spinner("ç”Ÿæˆç»´æŒå»ºè®®..." if st.session_state.language == 'ä¸­æ–‡' else "Generating maintenance suggestions..."):
                            counterfactual_results = perform_counterfactual_analysis(
                                model=model,
                                input_data=input_data,
                                original_prediction=prediction,
                                feature_names=model.feature_names_in_,
                                burn_type_mapping=burn_type_mapping,
                                shap_results=shap_results,
                                graph_results=graph_results
                            )
                            
                            # æ·»åŠ è°ƒè¯•ä¿¡æ¯
                            st.write("ğŸ” åäº‹å®åˆ†æç»“æœï¼ˆæ­£å¸¸ç»„ç»‡ï¼‰:")
                            st.write(f"æ˜¯å¦æœ‰æ­£å¸¸ç»„ç»‡å»ºè®®: {counterfactual_results.get('has_normal_tissue_suggestions', False)}")
                            st.write(f"æ­£å¸¸ç»„ç»‡å»ºè®®æ•°é‡: {len(counterfactual_results.get('normal_tissue_suggestions', []))}")
                    
                    # æ˜¾ç¤ºSHAPåˆ†æç»“æœ
                    if shap_results:
                        if st.session_state.language == 'ä¸­æ–‡':
                            st.markdown("##### ğŸ“ˆ SHAPå¤šç±»åˆ«åˆ†æ")
                        else:
                            st.markdown("##### ğŸ“ˆ SHAP Multi-Class Analysis")
                        
                        col_shap1, col_shap2 = st.columns([1, 1])
                        
                        with col_shap1:
                            # å›¾1: åˆå¹¶çš„SHAPåˆ†æå›¾è¡¨
                            fig_combined = plot_combined_shap_analysis(shap_results, model.feature_names_in_, burn_type_mapping)
                            if fig_combined:
                                st.pyplot(fig_combined)
                                if st.session_state.language == 'ä¸­æ–‡':
                                    st.caption("å›¾1: SHAPåˆå¹¶åˆ†æ - ç‰¹å¾å½±å“æ–¹å‘å’Œé‡è¦æ€§")
                                else:
                                    st.caption("Figure 1: Combined SHAP Analysis - Feature Impact and Importance")
                        
                        with col_shap2:
                            # å›¾2: å½“å‰é¢„æµ‹ç±»åˆ«çš„ç‰¹å¾é‡è¦æ€§å›¾
                            fig_current = plot_current_prediction_shap(shap_results, model.feature_names_in_, burn_type_mapping)
                            if fig_current:
                                st.pyplot(fig_current)
                                if st.session_state.language == 'ä¸­æ–‡':
                                    st.caption("å›¾2: å½“å‰é¢„æµ‹ç±»åˆ«ç‰¹å¾é‡è¦æ€§åˆ†æ")
                                else:
                                    st.caption("Figure 2: Feature Importance for Current Prediction")
                    
                    # æ˜¾ç¤ºå›¾ç½‘ç»œåˆ†æç»“æœ
                    if graph_results:
                        if st.session_state.language == 'ä¸­æ–‡':
                            st.markdown("##### ğŸ”— ç‰¹å¾å…³è”å›¾ç½‘ç»œåˆ†æ")
                        else:
                            st.markdown("##### ğŸ”— Feature Correlation Graph Analysis")
                        
                        graph_fig = plot_optimized_graph_analysis(graph_results, model.feature_names_in_, burn_info)
                        if graph_fig:
                            st.pyplot(graph_fig)
                    
                    # æ˜¾ç¤ºåäº‹å®åˆ†æç»“æœ - ä¿®æ”¹åˆ¤æ–­æ¡ä»¶
                    if (counterfactual_results and 
                        not counterfactual_results.get('skip_analysis', False)):
                        
                        # æ£€æŸ¥æ˜¯å¦æœ‰ä»»ä½•å»ºè®®
                        has_suggestions = (
                            counterfactual_results.get('has_normal_tissue_suggestions', False) or
                            counterfactual_results.get('normal_tissue_suggestions', []) or
                            counterfactual_results.get('milder_suggestions', []) or
                            counterfactual_results.get('all_counterfactuals', [])
                        )
                        
                        if has_suggestions:
                            if st.session_state.language == 'ä¸­æ–‡':
                                st.markdown("##### ğŸ”„ çƒ§ä¼¤ç­‰çº§æ”¹å–„ç­–ç•¥åˆ†æ")
                            else:
                                st.markdown("##### ğŸ”„ Burn Level Improvement Strategy Analysis")
                            
                            # æ˜¾ç¤ºå›¾è¡¨
                            counterfactual_fig = plot_optimized_counterfactual_analysis(counterfactual_results, burn_type_mapping)
                            if counterfactual_fig:
                                st.pyplot(counterfactual_fig)
                            
                            # æ˜¾ç¤ºæ–‡å­—å»ºè®®
                            if st.session_state.language == 'ä¸­æ–‡':
                                if counterfactual_results.get('has_normal_tissue_suggestions', False):
                                    suggestions = counterfactual_results.get('normal_tissue_suggestions', [])
                                    if suggestions:
                                        st.markdown("###### ğŸ’¡ æ¢å¤åˆ°æ­£å¸¸ç»„ç»‡çš„è°ƒæ•´å»ºè®®:")
                                        for i, suggestion in enumerate(suggestions[:3], 1):
                                            st.markdown(f"""
                                            <div class="analysis-box">
                                            <strong>æ–¹æ¡ˆ {i}:</strong> å°† <strong>{suggestion.get('feature', 'æœªçŸ¥')}</strong> {suggestion.get('direction', 'è°ƒæ•´')}åˆ°åŸæ¥çš„ <strong>{suggestion.get('change_factor', 1.0):.1f}å€</strong><br>
                                            - åŸå§‹å€¼: {suggestion.get('original_value', 0):.10f} â†’ ç›®æ ‡å€¼: {suggestion.get('new_value', 0):.10f}<br>
                                            - é¢„æµ‹ç½®ä¿¡åº¦: {suggestion.get('confidence', 0):.2%}<br>
                                            - æ”¹å–„ç¨‹åº¦: {suggestion.get('improvement', 0):.0f}åˆ†<br>
                                            - æ•ˆæœ: é¢„æµ‹ç»“æœä» <strong>{burn_type_mapping[counterfactual_results.get('original_prediction', 0)]['cn']}</strong> æ¢å¤åˆ° <strong>æ­£å¸¸ç»„ç»‡</strong>
                                            </div>
                                            """, unsafe_allow_html=True)
                                    
                                elif counterfactual_results.get('milder_suggestions', []):
                                    suggestions = counterfactual_results.get('milder_suggestions', [])
                                    if suggestions:
                                        st.markdown("###### ğŸ’¡ æ”¹å–„ä¸ºæ›´è½»åº¦çƒ§ä¼¤çš„å»ºè®®:")
                                        for i, suggestion in enumerate(suggestions[:3], 1):
                                            st.markdown(f"""
                                            <div class="analysis-box">
                                            <strong>æ–¹æ¡ˆ {i}:</strong> å°† <strong>{suggestion.get('feature', 'æœªçŸ¥')}</strong> {suggestion.get('direction', 'è°ƒæ•´')}åˆ°åŸæ¥çš„ <strong>{suggestion.get('change_factor', 1.0):.1f}å€</strong><br>
                                            - åŸå§‹å€¼: {suggestion.get('original_value', 0):.10f} â†’ ç›®æ ‡å€¼: {suggestion.get('new_value', 0):.10f}<br>
                                            - é¢„æµ‹ç½®ä¿¡åº¦: {suggestion.get('confidence', 0):.2%}<br>
                                            - æ”¹å–„ç¨‹åº¦: ä» <strong>{burn_type_mapping[counterfactual_results.get('original_prediction', 0)]['cn']}</strong> æ”¹å–„åˆ° <strong>{suggestion.get('target_name', 'æœªçŸ¥')}</strong>
                                            </div>
                                            """, unsafe_allow_html=True)
                            else:
                                # è‹±æ–‡ç‰ˆæœ¬
                                if counterfactual_results.get('has_normal_tissue_suggestions', False):
                                    suggestions = counterfactual_results.get('normal_tissue_suggestions', [])
                                    if suggestions:
                                        st.markdown("###### ğŸ’¡ Adjustment suggestions to restore normal tissue:")
                                        for i, suggestion in enumerate(suggestions[:3], 1):
                                            st.markdown(f"""
                                            <div class="analysis-box">
                                            <strong>Scenario {i}:</strong> Change <strong>{suggestion.get('feature', 'Unknown')}</strong> to <strong>{suggestion.get('change_factor', 1.0):.1f}x</strong> of original<br>
                                            - Original value: {suggestion.get('original_value', 0):.10f} â†’ Target value: {suggestion.get('new_value', 0):.10f}<br>
                                            - Prediction confidence: {suggestion.get('confidence', 0):.2%}<br>
                                            - Improvement score: {suggestion.get('improvement', 0):.0f} points<br>
                                            - Effect: Prediction changes from <strong>{burn_type_mapping[counterfactual_results.get('original_prediction', 0)]['en']}</strong> to <strong>Normal Tissue</strong>
                                            </div>
                                            """, unsafe_allow_html=True)
                                    
                                elif counterfactual_results.get('milder_suggestions', []):
                                    suggestions = counterfactual_results.get('milder_suggestions', [])
                                    if suggestions:
                                        st.markdown("###### ğŸ’¡ Suggestions to improve to milder burn:")
                                        for i, suggestion in enumerate(suggestions[:3], 1):
                                            st.markdown(f"""
                                            <div class="analysis-box">
                                            <strong>Scenario {i}:</strong> Change <strong>{suggestion.get('feature', 'Unknown')}</strong> to <strong>{suggestion.get('change_factor', 1.0):.1f}x</strong> of original<br>
                                            - Original value: {suggestion.get('original_value', 0):.10f} â†’ Target value: {suggestion.get('new_value', 0):.10f}<br>
                                            - Prediction confidence: {suggestion.get('confidence', 0):.2%}<br>
                                            - Improvement: From <strong>{burn_type_mapping[counterfactual_results.get('original_prediction', 0)]['en']}</strong> to <strong>{suggestion.get('target_name', 'Unknown')}</strong>
                                            </div>
                                            """, unsafe_allow_html=True)
                        
                        else:
                            if st.session_state.language == 'ä¸­æ–‡':
                                st.info("âš ï¸ æœªæ‰¾åˆ°å¯è¡Œçš„ç‰¹å¾è°ƒæ•´æ–¹æ¡ˆï¼Œå»ºè®®ç»“åˆä¸´åºŠè¯„ä¼°è¿›è¡Œä¸ªä½“åŒ–æ²»ç–—ã€‚")
                            else:
                                st.info("âš ï¸ No feasible feature adjustment solutions found. Consider personalized treatment based on clinical evaluation.")
                    
                    # æ¦‚ç‡åˆ†å¸ƒå›¾
                    st.markdown("---")
                    if st.session_state.language == 'ä¸­æ–‡':
                        st.markdown('<div class="sub-header">ğŸ“ˆ æ¦‚ç‡åˆ†å¸ƒåˆ†æ</div>', unsafe_allow_html=True)
                    else:
                        st.markdown('<div class="sub-header">ğŸ“ˆ Probability Distribution Analysis</div>', unsafe_allow_html=True)
                    
                    # è·å–å­—ä½“è®¾ç½®
                    font_settings = get_chart_font_settings()
                    
                    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
                    if st.session_state.language == 'ä¸­æ–‡':
                        title1, title2, ylabel = 'çƒ§ä¼¤ç±»å‹æ¦‚ç‡åˆ†å¸ƒ', 'æ¦‚ç‡åˆ†å¸ƒé¥¼å›¾', 'æ¦‚ç‡'
                        labels = [burn_type_mapping[i]['cn'] for i in range(len(probabilities))]
                    else:
                        title1, title2, ylabel = 'Burn Type Probability Distribution', 'Probability Distribution Pie Chart', 'Probability'
                        labels = [burn_type_mapping[i]['en'] for i in range(len(probabilities))]
                    
                    colors = st.session_state.chart_colors[:len(probabilities)]
                    bars = ax1.bar(range(len(probabilities)), probabilities, color=colors)
                    ax1.set_title(title1, fontfamily=font_settings['title_font']['family'],
                                 fontsize=font_settings['title_font']['size'])
                    ax1.set_xticks(range(len(probabilities)))
                    ax1.set_xticklabels(labels, rotation=45, ha='right', 
                                       fontfamily=font_settings['tick_font']['family'])
                    ax1.set_ylabel(ylabel, fontfamily=font_settings['axis_font']['family'],
                                 fontsize=font_settings['axis_font']['size'])
                    ax1.set_ylim(0, 1)
                    
                    for bar in bars:
                        height = bar.get_height()
                        ax1.text(bar.get_x() + bar.get_width()/2., height + 0.01, f'{height:.1%}', 
                                ha='center', va='bottom', fontfamily=font_settings['label_font']['family'])
                    
                    ax2.pie(probabilities, labels=labels, autopct='%1.1f%%', colors=colors, startangle=90,
                           textprops={'fontfamily': font_settings['label_font']['family']})
                    ax2.set_title(title2, fontfamily=font_settings['title_font']['family'],
                                 fontsize=font_settings['title_font']['size'])
                    
                    # åº”ç”¨å­—ä½“è®¾ç½®
                    apply_chart_font_settings(ax1, title=title1, ylabel=ylabel)
                    apply_chart_font_settings(ax2, title=title2)
                    
                    plt.tight_layout()
                    st.pyplot(fig)
                    
                    # ç»“æœå¯¼å‡º - ä¿®æ”¹1ï¼šä½¿ç”¨å¢å¼ºçš„åŒ»ç–—æŠ¥å‘Š
                    st.markdown("---")
                    if st.session_state.language == 'ä¸­æ–‡':
                        st.markdown('<div class="sub-header">ğŸ’¾ ç»“æœå¯¼å‡º</div>', unsafe_allow_html=True)
                    else:
                        st.markdown('<div class="sub-header">ğŸ’¾ Export Results</div>', unsafe_allow_html=True)
                    
                    # ç”Ÿæˆå¢å¼ºçš„åŒ»ç–—æŠ¥å‘Š
                    report_text = generate_medical_report(input_data, prediction, probabilities, shap_results, graph_results, counterfactual_results, burn_type_mapping, model.feature_names_in_, st.session_state.language)
                    
                    col_exp1, col_exp2, col_exp3 = st.columns(3)
                    with col_exp1:
                        csv_data = input_data.copy()
                        csv_data['é¢„æµ‹ç±»å‹' if st.session_state.language == 'ä¸­æ–‡' else 'Predicted Type'] = burn_info['cn' if st.session_state.language == 'ä¸­æ–‡' else 'en']
                        csv_data['ç½®ä¿¡åº¦' if st.session_state.language == 'ä¸­æ–‡' else 'Confidence'] = probabilities[prediction]
                        csv = csv_data.to_csv(index=False).encode('utf-8')
                        st.download_button(
                            label="ğŸ“¥ å¯¼å‡ºCSV" if st.session_state.language == 'ä¸­æ–‡' else "ğŸ“¥ Export CSV",
                            data=csv, file_name="burn_analysis_result.csv", mime="text/csv", use_container_width=True
                        )
                    with col_exp2:
                        buf = io.BytesIO()
                        fig.savefig(buf, format="png", dpi=300, bbox_inches='tight')
                        st.download_button(
                            label="ğŸ–¼ï¸ å¯¼å‡ºå›¾è¡¨" if st.session_state.language == 'ä¸­æ–‡' else "ğŸ–¼ï¸ Export Chart",
                            data=buf.getvalue(), file_name="burn_analysis_chart.png", mime="image/png", use_container_width=True
                        )
                    with col_exp3:
                        st.download_button(
                            label="ğŸ“„ å¯¼å‡ºåŒ»ç–—æŠ¥å‘Š" if st.session_state.language == 'ä¸­æ–‡' else "ğŸ“„ Export Medical Report",
                            data=report_text.encode('utf-8'), file_name="burn_medical_report.txt", mime="text/plain", use_container_width=True
                        )
                    
            except Exception as e:
                st.error(f"åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")

    with tab2:
        if st.session_state.language == 'ä¸­æ–‡':
            st.markdown('<div class="sub-header">ğŸ“ æ‰¹é‡æ•°æ®å¤„ç†</div>', unsafe_allow_html=True)
        else:
            st.markdown('<div class="sub-header">ğŸ“ Batch Data Processing</div>', unsafe_allow_html=True)
        st.info("æ‰¹é‡åˆ†æåŠŸèƒ½")

elif app_mode == "ğŸ“– ä½¿ç”¨æŒ‡å—":
    st.markdown('<div class="main-header">ğŸ“– ä½¿ç”¨æŒ‡å—</div>', unsafe_allow_html=True)
    
    # åˆ›å»ºæ ‡ç­¾é¡µ
    tab_guide1, tab_guide2, tab_guide3, tab_guide4, tab_guide5 = st.tabs(["ğŸ“‹ ç³»ç»Ÿä»‹ç»", "ğŸ”¬ ä½¿ç”¨æ­¥éª¤", "ğŸ“Š æ•°æ®è¯´æ˜", "ğŸ§  ç®—æ³•åŸç†", "â“ å¸¸è§é—®é¢˜"])
    
    with tab_guide1:
        st.markdown('<div class="guide-section">', unsafe_allow_html=True)
        st.markdown("## ğŸ”¬ ç³»ç»Ÿä»‹ç»")
        st.markdown("""
        æœ¬ç³»ç»ŸåŸºäºæœºå™¨å­¦ä¹ ç®—æ³•ï¼Œé€šè¿‡å¯¹ç”Ÿç‰©æ ‡å¿—ç‰©çš„åˆ†æï¼Œå®ç°çƒ§ä¼¤ç±»å‹çš„æ™ºèƒ½è¯†åˆ«å’Œåˆ†ç±»ã€‚ç³»ç»Ÿé›†æˆäº†å…ˆè¿›çš„æ¨¡å‹å¯è§£é‡Šæ€§æŠ€æœ¯ï¼Œ
        åŒ…æ‹¬SHAPåˆ†æã€å›¾ç½‘ç»œåˆ†æå’Œåäº‹å®åˆ†æï¼Œä¸ºåŒ»ç–—ä¸“ä¸šäººå‘˜æä¾›å…¨é¢çš„å†³ç­–æ”¯æŒã€‚
        """)
        st.markdown('</div>', unsafe_allow_html=True)
        
        col_intro1, col_intro2 = st.columns(2)
        with col_intro1:
            st.markdown('<div class="feature-box">', unsafe_allow_html=True)
            st.markdown("### ğŸ¯ ç³»ç»Ÿç‰¹è‰²")
            st.markdown("""
            - **æ™ºèƒ½è¯†åˆ«**: åŸºäºéšæœºæ£®æ—ç®—æ³•çš„å¤šåˆ†ç±»æ¨¡å‹
            - **å¯è§£é‡Šæ€§**: é›†æˆSHAPã€å›¾ç½‘ç»œã€åäº‹å®åˆ†æ
            - **é«˜ç²¾åº¦**: æ”¯æŒå°æ•°ç‚¹å10ä½çš„æ•°æ®ç²¾åº¦
            - **å¯è§†åŒ–**: ä¸°å¯Œçš„å›¾è¡¨å’Œäº¤äº’ç•Œé¢
            - **å¤šè¯­è¨€**: æ”¯æŒä¸­è‹±æ–‡ç•Œé¢åˆ‡æ¢
            """)
            st.markdown('</div>', unsafe_allow_html=True)
        
        with col_intro2:
            st.markdown('<div class="feature-box">', unsafe_allow_html=True)
            st.markdown("### ğŸ“Š åŠŸèƒ½æ¨¡å—")
            st.markdown("""
            - **å•æ ·æœ¬åˆ†æ**: å•ä¸ªæ ·æœ¬çš„è¯¦ç»†åˆ†æ
            - **æ‰¹é‡åˆ†æ**: æ‰¹é‡æ•°æ®å¤„ç†åŠŸèƒ½
            - **é«˜çº§åˆ†æ**: SHAP+å›¾ç½‘ç»œ+åäº‹å®åˆ†æ
            - **ç»“æœå¯¼å‡º**: æ”¯æŒCSVã€å›¾è¡¨ã€æŠ¥å‘Šå¯¼å‡º
            - **ç³»ç»Ÿè®¾ç½®**: ä¸ªæ€§åŒ–ç•Œé¢é…ç½®
            """)
            st.markdown('</div>', unsafe_allow_html=True)
    
    with tab_guide2:
        st.markdown('<div class="guide-section">', unsafe_allow_html=True)
        st.markdown("## ğŸ”¬ ä½¿ç”¨æ­¥éª¤")
        
        st.markdown("### 1. å•æ ·æœ¬åˆ†æ")
        steps = [
            ("ğŸ“‹ è¾“å…¥å‚æ•°", "åœ¨å•æ ·æœ¬åˆ†æé¡µé¢è¾“å…¥å››ä¸ªç”Ÿç‰©æ ‡å¿—ç‰©çš„æ•°å€¼"),
            ("ğŸš€ å¼€å§‹åˆ†æ", "ç‚¹å‡»å¼€å§‹åˆ†ææŒ‰é’®è·å–é¢„æµ‹ç»“æœ"),
            ("ğŸ“Š æŸ¥çœ‹ç»“æœ", "æŸ¥çœ‹è¯Šæ–­ç»“æœã€æ¦‚ç‡åˆ†å¸ƒå’Œç½®ä¿¡åº¦"),
            ("ğŸ”¬ é«˜çº§åˆ†æ", "å¯é€‰æ‰§è¡ŒSHAPã€å›¾ç½‘ç»œã€åäº‹å®åˆ†æ"),
            ("ğŸ’¾ å¯¼å‡ºç»“æœ", "å¯¼å‡ºCSVã€å›¾è¡¨å’Œåˆ†ææŠ¥å‘Š")
        ]
        
        for i, (step, desc) in enumerate(steps, 1):
            with st.expander(f"æ­¥éª¤ {i}: {step}"):
                st.markdown(desc)
        
        st.markdown("### 2. æ‰¹é‡åˆ†æ")
        st.markdown("""
        - å‡†å¤‡åŒ…å«BG1ã€EGFã€IL-1Î²ã€BG2åˆ—çš„CSVæˆ–Excelæ–‡ä»¶
        - åœ¨æ‰¹é‡åˆ†æé¡µé¢ä¸Šä¼ æ–‡ä»¶
        - ç³»ç»Ÿè‡ªåŠ¨å¤„ç†æ‰€æœ‰æ•°æ®å¹¶ç”Ÿæˆåˆ†ææŠ¥å‘Š
        - ä¸‹è½½æ‰¹é‡åˆ†æç»“æœ
        """)
        st.markdown('</div>', unsafe_allow_html=True)
    
    with tab_guide3:
        st.markdown('<div class="guide-section">', unsafe_allow_html=True)
        st.markdown("## ğŸ“Š æ•°æ®è¯´æ˜")
        
        st.markdown("### ğŸ”¬ ç”Ÿç‰©æ ‡å¿—ç‰©å‚æ•°")
        biomarkers = [
            ("BG1", "ç”Ÿç‰©æ ‡å¿—ç‰©1", "åæ˜ ç»„ç»‡ç‚ç—‡çŠ¶æ€çš„å…³é”®æŒ‡æ ‡", "2.453646"),
            ("IL-1Î²", "ç™½ç»†èƒä»‹ç´ -1Î²", "ç‚ç—‡å› å­ï¼Œæµ“åº¦ä¸çƒ§ä¼¤ä¸¥é‡ç¨‹åº¦æ­£ç›¸å…³", "340.098941 pg/mL"),
            ("EGF", "è¡¨çš®ç”Ÿé•¿å› å­", "ä¿ƒè¿›ä¼¤å£æ„ˆåˆçš„é‡è¦å› å­", "535.07482 pg/mL"),
            ("BG2", "ç”Ÿç‰©æ ‡å¿—ç‰©2", "ç»„ç»‡ä¿®å¤å’Œå†ç”Ÿèƒ½åŠ›æŒ‡æ ‡", "-0.179002")
        ]
        
        for biomarker, name, desc, example in biomarkers:
            with st.expander(f"{biomarker}: {name}"):
                st.markdown(f"**æè¿°**: {desc}")
                st.markdown(f"**ç¤ºä¾‹å€¼**: {example}")
                st.markdown(f"**æ•°æ®ç²¾åº¦**: æ”¯æŒå°æ•°ç‚¹å10ä½")
        
        st.markdown("### ğŸ“ˆ çƒ§ä¼¤ç±»å‹è¯´æ˜")
        for burn_id, burn_info in burn_type_mapping.items():
            st.markdown(f"""
            <div class="feature-box">
            <strong>{burn_info['cn']}</strong> ({burn_info['en']})
            - <em>æè¿°</em>: {burn_info['description']}
            - <em>é¢œè‰²æ ‡è¯†</em>: <span style="color:{burn_info['color']}">â—</span>
            </div>
            """, unsafe_allow_html=True)
        st.markdown('</div>', unsafe_allow_html=True)
    
    with tab_guide4:
        st.markdown('<div class="guide-section">', unsafe_allow_html=True)
        st.markdown("## ğŸ§  ç®—æ³•åŸç†")
        
        st.markdown("### ğŸ“ˆ SHAP (SHapley Additive exPlanations) åˆ†æ")
        st.markdown('<div class="theory-box">', unsafe_allow_html=True)
        st.markdown("""
        **ç†è®ºåŸºç¡€**: åŸºäºåšå¼ˆè®ºçš„Shapleyå€¼ï¼Œå…¬å¹³åˆ†é…æ¯ä¸ªç‰¹å¾å¯¹é¢„æµ‹ç»“æœçš„è´¡çŒ®åº¦
        
        **æ ¸å¿ƒåŸç†**:
        - è®¡ç®—æ¯ä¸ªç‰¹å¾åœ¨æ‰€æœ‰å¯èƒ½çš„ç‰¹å¾å­é›†ä¸­çš„è¾¹é™…è´¡çŒ®
        - é€šè¿‡åŠ æƒå¹³å‡å¾—åˆ°ç‰¹å¾çš„SHAPå€¼
        - æ­£å€¼è¡¨ç¤ºå¢åŠ é¢„æµ‹æ¦‚ç‡ï¼Œè´Ÿå€¼è¡¨ç¤ºå‡å°‘é¢„æµ‹æ¦‚ç‡
        
        **æ•°å­¦å…¬å¼**:
        """)
        st.markdown('<div class="code-box">Ï•áµ¢ = Î£ [f(S âˆª {i}) - f(S)] Ã— |S|! Ã— (|F| - |S| - 1)! / |F|!</div>', unsafe_allow_html=True)
        st.markdown("""
        **åº”ç”¨ä»·å€¼**:
        - ç†è§£æ¨¡å‹å†³ç­–ä¾æ®
        - è¯†åˆ«å…³é”®å½±å“å› ç´ 
        - æä¾›ç‰¹å¾é‡è¦æ€§æ’åº
        """)
        st.markdown('</div>', unsafe_allow_html=True)
        
        st.markdown("### ğŸ”— å›¾ç½‘ç»œåˆ†æ")
        st.markdown('<div class="theory-box">', unsafe_allow_html=True)
        st.markdown("""
        **ç†è®ºåŸºç¡€**: å¤æ‚ç½‘ç»œç†è®ºï¼Œå°†ç‰¹å¾è§†ä¸ºèŠ‚ç‚¹ï¼Œç‰¹å¾é—´å…³ç³»è§†ä¸ºè¾¹
        
        **æ ¸å¿ƒæŒ‡æ ‡**:
        - **åº¦ä¸­å¿ƒæ€§**: èŠ‚ç‚¹è¿æ¥æ•°é‡ï¼Œåæ˜ ç‰¹å¾æ´»è·ƒåº¦
        - **ä»‹æ•°ä¸­å¿ƒæ€§**: èŠ‚ç‚¹åœ¨ç½‘ç»œä¸­çš„æ¡¥æ¢ä½œç”¨
        - **ç´§å¯†ä¸­å¿ƒæ€§**: èŠ‚ç‚¹åˆ°å…¶ä»–èŠ‚ç‚¹çš„å¹³å‡è·ç¦»
        
        **ç½‘ç»œæ„å»º**:
        - èŠ‚ç‚¹: ç”Ÿç‰©æ ‡å¿—ç‰©ç‰¹å¾
        - è¾¹: ç‰¹å¾é—´çš„ç›¸å…³æ€§å¼ºåº¦
        - æƒé‡: åŸºäºç‰¹å¾å€¼ç›¸ä¼¼åº¦è®¡ç®—
        
        **åº”ç”¨ä»·å€¼**:
        - æ­ç¤ºç‰¹å¾é—´ç›¸äº’ä½œç”¨å…³ç³»
        - è¯†åˆ«ç½‘ç»œä¸­çš„å…³é”®æ¢çº½ç‰¹å¾
        - ç†è§£ç‰¹å¾ç³»ç»Ÿçš„æ•´ä½“ç»“æ„
        """)
        st.markdown('</div>', unsafe_allow_html=True)
        
        st.markdown("### ğŸ”„ åäº‹å®åˆ†æ")
        st.markdown('<div class="theory-box">', unsafe_allow_html=True)
        st.markdown("""
        **ç†è®ºåŸºç¡€**: å› æœæ¨ç†ï¼Œé€šè¿‡æ”¹å˜è¾“å…¥ç‰¹å¾è§‚å¯Ÿé¢„æµ‹ç»“æœå˜åŒ–
        
        **åˆ†ææ–¹æ³•**:
        - å¯¹æ¯ä¸ªç‰¹å¾è¿›è¡Œå¾®å°è°ƒæ•´ï¼ˆå¦‚Â±20%ã€Â±50%ï¼‰
        - è§‚å¯Ÿé¢„æµ‹ç»“æœçš„å˜åŒ–
        - å¯»æ‰¾æ”¹å˜é¢„æµ‹çš„æœ€å°ç‰¹å¾è°ƒæ•´
        
        **æ•°å­¦è¡¨è¾¾**:
        """)
        st.markdown('<div class="code-box">x\' = x + Î´ â†’ æ£€æŸ¥ f(x\') æ˜¯å¦ â‰  f(x)</div>', unsafe_allow_html=True)
        st.markdown("""
        **åº”ç”¨ä»·å€¼**:
        - æä¾›å¹²é¢„ç­–ç•¥å»ºè®®
        - ç†è§£å†³ç­–è¾¹ç•Œ
        - å‘ç°æ¨¡å‹çš„æ•æ„Ÿç‰¹å¾
        - ä¸ºä¸´åºŠå¹²é¢„æä¾›é‡åŒ–ä¾æ®
        """)
        st.markdown('</div>', unsafe_allow_html=True)
        
        st.markdown("### ğŸŒ³ éšæœºæ£®æ—ç®—æ³•")
        st.markdown('<div class="theory-box">', unsafe_allow_html=True)
        st.markdown("""
        **ç®—æ³•åŸç†**: é›†æˆå­¦ä¹ ï¼Œé€šè¿‡å¤šä¸ªå†³ç­–æ ‘çš„é›†ä½“å†³ç­–æé«˜é¢„æµ‹å‡†ç¡®æ€§
        
        **æ ¸å¿ƒç‰¹ç‚¹**:
        - **Bagging**: è‡ªåŠ©é‡‡æ ·æ„å»ºå¤šä¸ªå†³ç­–æ ‘
        - **ç‰¹å¾éšæœºæ€§**: æ¯ä¸ªèŠ‚ç‚¹åˆ†è£‚æ—¶éšæœºé€‰æ‹©ç‰¹å¾å­é›†
        - **æŠ•ç¥¨æœºåˆ¶**: å¤šæ£µæ ‘æŠ•ç¥¨å†³å®šæœ€ç»ˆé¢„æµ‹ç»“æœ
        
        **ä¼˜åŠ¿**:
        - æŠ—è¿‡æ‹Ÿåˆèƒ½åŠ›å¼º
        - å¤„ç†é«˜ç»´æ•°æ®æ•ˆæœå¥½
        - æä¾›ç‰¹å¾é‡è¦æ€§è¯„ä¼°
        - å¯¹å¼‚å¸¸å€¼ä¸æ•æ„Ÿ
        """)
        st.markdown('</div>', unsafe_allow_html=True)
        st.markdown('</div>', unsafe_allow_html=True)
    
    with tab_guide5:
        st.markdown('<div class="guide-section">', unsafe_allow_html=True)
        st.markdown("## â“ å¸¸è§é—®é¢˜")
        
        faqs = [
            ("â“ ç³»ç»Ÿæ”¯æŒçš„æ•°æ®æ ¼å¼æœ‰å“ªäº›ï¼Ÿ", "æ”¯æŒCSVå’ŒExcelæ ¼å¼ï¼Œéœ€è¦åŒ…å«BG1ã€EGFã€IL-1Î²ã€BG2å››åˆ—æ•°æ®"),
            ("â“ æ•°æ®ç²¾åº¦å¯ä»¥è°ƒæ•´å—ï¼Ÿ", "æ”¯æŒå°æ•°ç‚¹å6-15ä½ç²¾åº¦ï¼Œå¯åœ¨ç³»ç»Ÿè®¾ç½®ä¸­è°ƒæ•´"),
            ("â“ SHAPåˆ†æéœ€è¦å¤šå°‘æ ·æœ¬ï¼Ÿ", "å•æ ·æœ¬å³å¯è¿›è¡ŒSHAPåˆ†æï¼Œå¤šæ ·æœ¬å¯æä¾›æ›´ç¨³å®šçš„ç»“æœ"),
            ("â“ å¦‚ä½•è§£é‡Šåäº‹å®åˆ†æç»“æœï¼Ÿ", "åäº‹å®åˆ†ææ˜¾ç¤ºå¦‚ä½•è°ƒæ•´ç‰¹å¾å€¼æ¥æ”¹å˜é¢„æµ‹ç»“æœï¼Œä¸ºå¹²é¢„æä¾›ä¾æ®"),
            ("â“ ç³»ç»Ÿæ”¯æŒå“ªäº›è¯­è¨€ï¼Ÿ", "æ”¯æŒä¸­æ–‡å’Œè‹±æ–‡ç•Œé¢ï¼Œå¯åœ¨ç³»ç»Ÿè®¾ç½®ä¸­åˆ‡æ¢"),
            ("â“ åˆ†æç»“æœå¯ä»¥å¯¼å‡ºå—ï¼Ÿ", "æ”¯æŒå¯¼å‡ºCSVæ•°æ®ã€PNGå›¾è¡¨å’Œæ–‡æœ¬æŠ¥å‘Š")
        ]
        
        for question, answer in faqs:
            with st.expander(question):
                st.markdown(answer)
        st.markdown('</div>', unsafe_allow_html=True)

elif app_mode == "âš™ï¸ ç³»ç»Ÿè®¾ç½®":
    st.markdown('<div class="main-header">âš™ï¸ ç³»ç»Ÿè®¾ç½®</div>', unsafe_allow_html=True)
    
    # è¯­è¨€è®¾ç½®
    st.subheader("ğŸŒ è¯­è¨€è®¾ç½®")
    # ä¿®å¤ï¼šæ·»åŠ å”¯ä¸€çš„keyå‚æ•°
    language = st.selectbox("é€‰æ‹©ç•Œé¢è¯­è¨€", ["ä¸­æ–‡", "English"], key="system_language_select")
    
    if st.button("ğŸ’¾ åº”ç”¨è¯­è¨€è®¾ç½®", use_container_width=True, key="apply_language_btn"):
        st.session_state.language = language
        st.success("âœ… è¯­è¨€è®¾ç½®å·²åº”ç”¨")
    
    st.markdown("---")
    
    # å›¾è¡¨é¢œè‰²è®¾ç½®
    st.subheader("ğŸ¨ å›¾è¡¨é¢œè‰²è®¾ç½®")
    
    st.info("å½“å‰ä½¿ç”¨Natureé…è‰²æ–¹æ¡ˆ: #4E79A7, #F28E2B, #E15759, #76B7B2, #59A14F, #EDC948")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        color1 = st.color_picker("é¢œè‰²1", value="#4E79A7", key="color1_picker")
    with col2:
        color2 = st.color_picker("é¢œè‰²2", value="#F28E2B", key="color2_picker")
    with col3:
        color3 = st.color_picker("é¢œè‰²3", value="#E15759", key="color3_picker")
    
    col4, col5, col6 = st.columns(3)
    
    with col4:
        color4 = st.color_picker("é¢œè‰²4", value="#76B7B2", key="color4_picker")
    with col5:
        color5 = st.color_picker("é¢œè‰²5", value="#59A14F", key="color5_picker")
    with col6:
        color6 = st.color_picker("é¢œè‰²6", value="#EDC948", key="color6_picker")
    
    st.markdown("---")
    
    # å›¾è¡¨å­—ä½“è®¾ç½®
    st.subheader("ğŸ”¤ å›¾è¡¨å­—ä½“è®¾ç½®")
    
    st.info("è®¾ç½®æ‰€æœ‰å›¾è¡¨ä¸­çš„æ ‡é¢˜ã€åæ ‡è½´ã€åˆ»åº¦å’Œæ ‡ç­¾çš„å­—ä½“æ ·å¼")
    
    col_font1, col_font2 = st.columns(2)
    
    with col_font1:
        st.markdown("#### æ ‡é¢˜å­—ä½“è®¾ç½®")
        # ä¿®å¤ï¼šæ·»åŠ å”¯ä¸€çš„keyå‚æ•°
        chart_title_family = st.selectbox("æ ‡é¢˜å­—ä½“", ["Microsoft YaHei", "SimHei", "SimSun", "Arial", "Times New Roman"], 
                                        key="chart_title_family_select")
        chart_title_size = st.slider("æ ‡é¢˜å­—å·", 10, 20, 14, key="chart_title_size_slider")
        chart_title_weight = st.selectbox("æ ‡é¢˜å­—é‡", ["normal", "bold"], key="chart_title_weight_select")
        
        st.markdown("#### åæ ‡è½´å­—ä½“è®¾ç½®")
        chart_axis_family = st.selectbox("åæ ‡è½´å­—ä½“", ["Microsoft YaHei", "SimHei", "SimSun", "Arial", "Times New Roman"], 
                                       key="chart_axis_family_select")
        chart_axis_size = st.slider("åæ ‡è½´å­—å·", 8, 16, 10, key="chart_axis_size_slider")
    
    with col_font2:
        st.markdown("#### åˆ»åº¦å­—ä½“è®¾ç½®")
        chart_tick_family = st.selectbox("åˆ»åº¦å­—ä½“", ["Microsoft YaHei", "SimHei", "SimSun", "Arial", "Times New Roman"], 
                                       key="chart_tick_family_select")
        chart_tick_size = st.slider("åˆ»åº¦å­—å·", 6, 14, 8, key="chart_tick_size_slider")
        
        st.markdown("#### æ ‡ç­¾å­—ä½“è®¾ç½®")
        chart_label_family = st.selectbox("æ ‡ç­¾å­—ä½“", ["Microsoft YaHei", "SimHei", "SimSun", "Arial", "Times New Roman"], 
                                       key="chart_label_family_select")
        chart_label_size = st.slider("æ ‡ç­¾å­—å·", 8, 16, 9, key="chart_label_size_slider")
    
    st.markdown("---")
    
    # æ•°æ®ç²¾åº¦è®¾ç½®
    st.subheader("ğŸ”¢ æ•°æ®ç²¾åº¦è®¾ç½®")
    
    data_precision_input = st.slider("æ•°æ®å°æ•°ç‚¹åä½æ•°", 6, 15, 10, key="data_precision_slider")
    st.info(f"å½“å‰æ•°æ®ç²¾åº¦: å°æ•°ç‚¹å{data_precision_input}ä½")
    
    # ä¸»é¢˜è®¾ç½®
    st.subheader("ğŸ­ ä¸»é¢˜è®¾ç½®")
    
    # ä¿®å¤ï¼šæ·»åŠ å”¯ä¸€çš„keyå‚æ•°
    theme = st.selectbox("é€‰æ‹©ç•Œé¢ä¸»é¢˜", ["æµ…è‰²ä¸»é¢˜", "æ·±è‰²ä¸»é¢˜"], key="theme_select")
    
    # åº”ç”¨è®¾ç½®æŒ‰é’®
    if st.button("ğŸ’¾ åº”ç”¨æ‰€æœ‰è®¾ç½®", use_container_width=True, key="apply_all_settings_btn"):
        # ä¿å­˜è®¾ç½®åˆ°session state
        st.session_state.chart_colors = [color1, color2, color3, color4, color5, color6]
        
        # ä¿å­˜å›¾è¡¨å­—ä½“è®¾ç½®
        st.session_state.chart_title_font = {
            'family': chart_title_family,
            'size': chart_title_size,
            'weight': chart_title_weight
        }
        st.session_state.chart_axis_font = {
            'family': chart_axis_family,
            'size': chart_axis_size
        }
        st.session_state.chart_tick_font = {
            'family': chart_tick_family,
            'size': chart_tick_size
        }
        st.session_state.chart_label_font = {
            'family': chart_label_family,
            'size': chart_label_size
        }
        
        st.session_state.current_data_precision = data_precision_input
        st.session_state.theme = theme
        st.success("âœ… æ‰€æœ‰è®¾ç½®å·²åº”ç”¨")
    
    # é‡ç½®è®¾ç½®ä¸ºé»˜è®¤å€¼
    if st.button("ğŸ”„ é‡ç½®ä¸ºé»˜è®¤è®¾ç½®", use_container_width=True, key="reset_defaults_btn"):
        st.session_state.chart_colors = ['#4E79A7', '#F28E2B', '#E15759', '#76B7B2', '#59A14F', '#EDC948']
        st.session_state.title_font = {'family': 'Microsoft YaHei', 'size': 14, 'weight': 'bold'}
        st.session_state.label_font = {'family': 'Microsoft YaHei', 'size': 10}
        st.session_state.current_data_precision = 10
        st.session_state.theme = 'light'
        st.success("âœ… å·²é‡ç½®ä¸ºé»˜è®¤è®¾ç½®")
    
    # å½“å‰è®¾ç½®é¢„è§ˆ
    st.markdown("---")
    st.subheader("ğŸ“Š å½“å‰è®¾ç½®é¢„è§ˆ")
    
    col_preview1, col_preview2 = st.columns(2)
    
    with col_preview1:
        st.markdown(f"""
        <div class="setting-box">
        <strong>å½“å‰è®¾ç½®:</strong>
        <ul>
        <li>è¯­è¨€: {st.session_state.language}</li>
        <li>ä¸»é¢˜: {st.session_state.theme}</li>
        <li>æ•°æ®ç²¾åº¦: å°æ•°ç‚¹å{getattr(st.session_state, 'current_data_precision', 10)}ä½</li>
        <li>å­—ä½“: {st.session_state.title_font['family']}</li>
        <li>æ ‡é¢˜å­—å·: {st.session_state.title_font['size']}</li>
        <li>æ ‡ç­¾å­—å·: {st.session_state.label_font['size']}</li>
        </ul>
        </div>
        """, unsafe_allow_html=True)
    
    with col_preview2:
        # é¢œè‰²é¢„è§ˆ
        st.markdown("**é¢œè‰²é¢„è§ˆ:**")
        colors_html = ""
        for i, color in enumerate(st.session_state.chart_colors):
            colors_html += f'<span style="display: inline-block; width: 20px; height: 20px; background-color: {color}; margin: 2px; border-radius: 3px;" title="é¢œè‰²{i+1}"></span>'
        st.markdown(f'<div>{colors_html}</div>', unsafe_allow_html=True)

# é¡µè„š
st.markdown("---")
st.markdown('<div style="text-align: center; color: #666; font-family: "Microsoft YaHei", sans-serif;">ğŸ”¥ çƒ§ä¼¤æ™ºèƒ½è¯†åˆ«ç³»ç»Ÿ | åŸºäºæœºå™¨å­¦ä¹ çš„åŒ»ç–—è¾…åŠ©è¯Šæ–­å·¥å…· | v1.0 | æœ¬åœ°éƒ¨ç½²ç‰ˆæœ¬</div>', unsafe_allow_html=True)